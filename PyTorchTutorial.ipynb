{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial Workthrough\n",
    "\n",
    "Here we work through a basic example in PyTorch. It is the example used in the [PyTorch Tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html). The material heavily relies on the excellent material in that tutorial. The presentation is similar but with a slightly different emphasis. In particular this is written from the perspective of an econometrician and some parallels and differences to traditional econometric techniques will be pointed out.\n",
    "\n",
    "\n",
    "## Load some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "The PyTorch library expects data inputs as tensors. For example, here we load some inflation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inflation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960-01-01</th>\n",
       "      <td>-0.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-01-02</th>\n",
       "      <td>0.341297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-01-03</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-01-04</th>\n",
       "      <td>0.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-01-05</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>0.331073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>0.505904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>0.251844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>0.322891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>0.190752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>763 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            inflation\n",
       "DATE                 \n",
       "1960-01-01  -0.340136\n",
       "1960-01-02   0.341297\n",
       "1960-01-03   0.000000\n",
       "1960-01-04   0.340136\n",
       "1960-01-05   0.000000\n",
       "...               ...\n",
       "2023-01-03   0.331073\n",
       "2023-01-04   0.505904\n",
       "2023-01-05   0.251844\n",
       "2023-01-06   0.322891\n",
       "2023-01-07   0.190752\n",
       "\n",
       "[763 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('datasets/CPALTT01USM657N.csv')\n",
    "data.tail()\n",
    "data['DATE'] = pd.to_datetime(data['DATE'])\n",
    "data.set_index('DATE', inplace=True)\n",
    "data.rename(columns={'CPALTT01USM657N': 'inflation'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can be transformed into a tensor like so, where we use the `values()` property of the dataframe. The resulting tensor has properties `shape` and `type` which give you the relevant shape and type information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([763, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor(data.values)\n",
    "tensor.dtype\n",
    "tensor.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are basically multi-dimensional matrices and you can do arithmatic with these. Find a [list of operations](https://pytorch.org/docs/stable/torch.html) to see what is available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data\n",
    "\n",
    "To follow the example in the PyTorch tutorial we need to load the Fashion-MNIST dataset. This dataset is already in the right format and we obtain a training and a testing portion for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are image data, for instance the first image `training_data[1]` gives you information on the 28x28 pixels of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.1608, 0.7373, 0.4039, 0.2118, 0.1882, 0.1686,\n",
       "           0.3412, 0.6588, 0.5216, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.5333, 0.8588, 0.8471, 0.8941, 0.9255, 1.0000, 1.0000, 1.0000,\n",
       "           1.0000, 0.8510, 0.8431, 0.9961, 0.9059, 0.6275, 0.1765, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.6902, 0.8706,\n",
       "           0.8784, 0.8314, 0.7961, 0.7765, 0.7686, 0.7843, 0.8431, 0.8000,\n",
       "           0.7922, 0.7882, 0.7882, 0.7882, 0.8196, 0.8549, 0.8784, 0.6431,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7373, 0.8588, 0.7843,\n",
       "           0.7765, 0.7922, 0.7765, 0.7804, 0.7804, 0.7882, 0.7686, 0.7765,\n",
       "           0.7765, 0.7843, 0.7843, 0.7843, 0.7843, 0.7882, 0.7843, 0.8824,\n",
       "           0.1608, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.8588, 0.7804, 0.7961,\n",
       "           0.7961, 0.8314, 0.9333, 0.9725, 0.9804, 0.9608, 0.9765, 0.9647,\n",
       "           0.9686, 0.9882, 0.9725, 0.9216, 0.8118, 0.7961, 0.7961, 0.8706,\n",
       "           0.5490, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.4549, 0.8863, 0.8078, 0.8000,\n",
       "           0.8118, 0.8000, 0.3961, 0.2941, 0.1843, 0.2863, 0.1882, 0.1961,\n",
       "           0.1765, 0.2000, 0.2471, 0.4431, 0.8706, 0.7922, 0.8078, 0.8627,\n",
       "           0.8784, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.7843, 0.8706, 0.8196, 0.7961,\n",
       "           0.8431, 0.7843, 0.0000, 0.2745, 0.3843, 0.0000, 0.4039, 0.2314,\n",
       "           0.2667, 0.2784, 0.1922, 0.0000, 0.8588, 0.8078, 0.8392, 0.8235,\n",
       "           0.9804, 0.1490, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9686, 0.8549, 0.8314, 0.8235,\n",
       "           0.8431, 0.8392, 0.0000, 0.9961, 0.9529, 0.5451, 1.0000, 0.6824,\n",
       "           0.9843, 1.0000, 0.8039, 0.0000, 0.8431, 0.8510, 0.8392, 0.8157,\n",
       "           0.8627, 0.3725, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.1765, 0.8863, 0.8392, 0.8392, 0.8431,\n",
       "           0.8784, 0.8039, 0.0000, 0.1647, 0.1373, 0.2353, 0.0627, 0.0667,\n",
       "           0.0471, 0.0510, 0.2745, 0.0000, 0.7412, 0.8471, 0.8314, 0.8078,\n",
       "           0.8314, 0.6118, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.6431, 0.9216, 0.8392, 0.8275, 0.8627,\n",
       "           0.8471, 0.7882, 0.2039, 0.2784, 0.3490, 0.3686, 0.3255, 0.3059,\n",
       "           0.2745, 0.2980, 0.3608, 0.3412, 0.8078, 0.8118, 0.8706, 0.8353,\n",
       "           0.8588, 0.8157, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.4157, 0.7333, 0.8745, 0.9294, 0.9725,\n",
       "           0.8275, 0.7765, 0.9882, 0.9804, 0.9725, 0.9608, 0.9725, 0.9882,\n",
       "           0.9922, 0.9804, 0.9882, 0.9373, 0.7882, 0.8314, 0.8824, 0.8431,\n",
       "           0.7569, 0.4431, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.2118, 0.6235,\n",
       "           0.8706, 0.7569, 0.8157, 0.7529, 0.7725, 0.7843, 0.7843, 0.7843,\n",
       "           0.7843, 0.7882, 0.7961, 0.7647, 0.8235, 0.6471, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843,\n",
       "           0.8824, 0.7529, 0.8392, 0.7961, 0.8078, 0.8000, 0.8000, 0.8039,\n",
       "           0.8078, 0.8000, 0.8314, 0.7725, 0.8549, 0.4196, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0235, 0.0000, 0.1804,\n",
       "           0.8314, 0.7647, 0.8314, 0.7922, 0.8078, 0.8039, 0.8000, 0.8039,\n",
       "           0.8078, 0.8000, 0.8314, 0.7843, 0.8549, 0.3569, 0.0000, 0.0118,\n",
       "           0.0039, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0431,\n",
       "           0.7725, 0.7804, 0.8039, 0.7922, 0.8039, 0.8078, 0.8000, 0.8039,\n",
       "           0.8118, 0.8000, 0.8039, 0.8039, 0.8549, 0.3020, 0.0000, 0.0196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.0078,\n",
       "           0.7490, 0.7765, 0.7882, 0.8039, 0.8078, 0.8039, 0.8039, 0.8078,\n",
       "           0.8196, 0.8078, 0.7804, 0.8196, 0.8588, 0.2902, 0.0000, 0.0196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000,\n",
       "           0.7373, 0.7725, 0.7843, 0.8118, 0.8118, 0.8000, 0.8118, 0.8118,\n",
       "           0.8235, 0.8157, 0.7765, 0.8118, 0.8667, 0.2824, 0.0000, 0.0157,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000,\n",
       "           0.8431, 0.7765, 0.7961, 0.8078, 0.8157, 0.8039, 0.8118, 0.8118,\n",
       "           0.8235, 0.8157, 0.7843, 0.7922, 0.8706, 0.2941, 0.0000, 0.0157,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.8314, 0.7765, 0.8196, 0.8078, 0.8196, 0.8078, 0.8157, 0.8118,\n",
       "           0.8275, 0.8078, 0.8039, 0.7765, 0.8667, 0.3137, 0.0000, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.8000, 0.7882, 0.8039, 0.8157, 0.8118, 0.8039, 0.8275, 0.8039,\n",
       "           0.8235, 0.8235, 0.8196, 0.7647, 0.8667, 0.3765, 0.0000, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.7922, 0.7882, 0.8039, 0.8196, 0.8118, 0.8039, 0.8353, 0.8078,\n",
       "           0.8235, 0.8196, 0.8235, 0.7608, 0.8510, 0.4118, 0.0000, 0.0078,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.8000, 0.8000, 0.8039, 0.8157, 0.8118, 0.8039, 0.8431, 0.8118,\n",
       "           0.8235, 0.8157, 0.8275, 0.7569, 0.8353, 0.4510, 0.0000, 0.0078,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.8000, 0.8118, 0.8118, 0.8157, 0.8078, 0.8078, 0.8431, 0.8235,\n",
       "           0.8235, 0.8118, 0.8314, 0.7647, 0.8235, 0.4627, 0.0000, 0.0078,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.7765, 0.8157, 0.8157, 0.8157, 0.8000, 0.8118, 0.8314, 0.8314,\n",
       "           0.8235, 0.8118, 0.8275, 0.7686, 0.8118, 0.4745, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.7765, 0.8235, 0.8118, 0.8157, 0.8078, 0.8196, 0.8353, 0.8314,\n",
       "           0.8275, 0.8118, 0.8235, 0.7725, 0.8118, 0.4863, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.6745, 0.8235, 0.7961, 0.7882, 0.7804, 0.8000, 0.8118, 0.8039,\n",
       "           0.8000, 0.7882, 0.8039, 0.7725, 0.8078, 0.4980, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.7373, 0.8667, 0.8392, 0.9176, 0.9255, 0.9333, 0.9569, 0.9569,\n",
       "           0.9569, 0.9412, 0.9529, 0.8392, 0.8784, 0.6353, 0.0000, 0.0078,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.5451, 0.5725, 0.5098, 0.5294, 0.5294, 0.5373, 0.4902, 0.4863,\n",
       "           0.4902, 0.4745, 0.4667, 0.4471, 0.5098, 0.2980, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the data avaialable in `test_data` and `training_data`. For certain operations it will turn out to be useful to access the data via the DataLoader. This will enable access samples of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indicated above that, if iterating through the data, we get random items. Each item has an image and a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = training_data[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations\n",
    "\n",
    "Neural Network models need data input in very controlled scales. Examples are standardised variables (mean 0 and variance 1) or data mapped into a $[0,1]$ interval. In fact, when we imported the Fashion data earlier, we called `transform=ToTensor()`. This ensured that the pixel information was mapped into the $[0,1]$ intervall. The `target` variable, which is the label, however, came as an integer in $[0,9]$. By reloading the data with the `target_transform` as below, we change the label into 10 indicator variables with all but one taking the value 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")\n",
    "\n",
    "ds_test = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us extract the 15th item out of `ds_train`, show it and see what type of item it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "img, label = ds_train[14]\n",
    "img = img.squeeze()\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the third last indicator variable is 1. That corresponds to label 7, a sneaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "\n",
    "Now that the data are prepared we need to build the model. This is done using the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will return to the details of the above setup a little later. For now just accept it.\n",
    "\n",
    "But what is useful to understand what the above code did. It defined a `class` called `NeuralNetwork`. This will allow us to soon define a particular object (in computing speak an \"instance\" of that type of object) of that class. More on this later. \n",
    "\n",
    "Estimating, or training in the language of machine learning, a neural network model can by computing intensive. So we want to use the best possible hardware to do so. The following bit of code checks whether you have any special resources available. If not, then your computer's CPU will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shall define one instance of the `NeuralNetwork` type of objects, and we call it `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the model eventually maps the 784 (28x28 pixels) into 10 output items (the 10 different labels). In other words, we feed in an image (as defined by 728 pixels) and we receive information in terms of 10 outputs (the 10 possible labels).\n",
    "\n",
    "Let us now define a random image and then we print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "plt.imshow(X.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is just noise. We shouldn't expect to see any particular item of clothing in here. But anyways, let's see whether our Neural Network can detect anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1036, 0.0926, 0.1085, 0.0980, 0.1054, 0.1057, 0.0985, 0.0863, 0.0991,\n",
      "         0.1022]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "print(pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you see here are the predicted probabilities for each of the 10 item classes (from t-shirt to ankle boots). You can see that these probabilities are all between 8 and 11% and in fact they sum to 1. This is not surprising as the random image does not look anythink like any of the items in our list. The max prob here is the probability of 10.55% for a bag.\n",
    "\n",
    "Let's see how the model does with one of our images from the test dataset (`ds_test`). We will pick the 15th image from the training dataset. We'll first print the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdoUlEQVR4nO3df2xV9f3H8dellEuB9roK7W0Hdo3DbRHCIjiQKBajlSYyEbegJlv5Y0YnkDRozBg62LJQQyZzC9NlZmGYyUayKZpIxE5oYUEWbHASdAxClU7oOhjcW2i5pe3n+wex35Xfnw/39t3bPh/JSey95+X5cDjlxeHe+27EOecEAICBYdYLAAAMXZQQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzAy3XsD5enp6dOTIEeXn5ysSiVgvBwDgyTmntrY2lZaWatiwy9/rDLgSOnLkiCZMmGC9DADANWpubtb48eMvu8+A++e4/Px86yUAANLgav48z1gJvfjiiyovL9fIkSM1depU7dix46py/BMcAAwOV/PneUZKaOPGjaqpqdHy5cu1Z88e3XHHHaqqqtLhw4czcTgAQJaKZGKK9vTp03XLLbfopZde6n3sa1/7mubNm6fa2trLZpPJpGKxWLqXBADoZ4lEQgUFBZfdJ+13Qp2dnWpsbFRlZWWfxysrK7Vz584L9k+lUkomk302AMDQkPYSOnbsmLq7u1VcXNzn8eLiYrW0tFywf21trWKxWO/GO+MAYOjI2BsTzn9Byjl30Repli1bpkQi0bs1NzdnakkAgAEm7Z8TGjt2rHJyci6462ltbb3g7kiSotGootFoupcBAMgCab8TGjFihKZOnaq6uro+j9fV1WnmzJnpPhwAIItlZGLC0qVL9Z3vfEfTpk3Tbbfdpt/85jc6fPiwHn/88UwcDgCQpTJSQgsWLNDx48f1k5/8REePHtWkSZO0efNmlZWVZeJwAIAslZHPCV0LPicEAIODyeeEAAC4WpQQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMDLdeADAUffvb3/bOPPbYY96Zjz76yDsjSe+++6535o033gg6FoY27oQAAGYoIQCAmbSX0MqVKxWJRPps8Xg83YcBAAwCGXlN6Oabb9Zf/vKX3q9zcnIycRgAQJbLSAkNHz6cux8AwBVl5DWhAwcOqLS0VOXl5XrooYd06NChS+6bSqWUTCb7bACAoSHtJTR9+nS98sor2rJli15++WW1tLRo5syZOn78+EX3r62tVSwW690mTJiQ7iUBAAaotJdQVVWVHnzwQU2ePFl333233nrrLUnS+vXrL7r/smXLlEgkerfm5uZ0LwkAMEBl/MOqo0eP1uTJk3XgwIGLPh+NRhWNRjO9DADAAJTxzwmlUil9/PHHKikpyfShAABZJu0l9NRTT6mhoUFNTU3629/+pm9961tKJpOqrq5O96EAAFku7f8c969//UsPP/ywjh07pnHjxmnGjBnatWuXysrK0n0oAECWizjnnPUi/lcymVQsFrNeBpBRP/vZz7wzs2bN8s50d3d7ZyRpxowZ3plf/OIX3pmamhrvzEA3evRo78wzzzzjnSkqKvLOSNLjjz/unTl79mzQsRKJhAoKCi67D7PjAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmGGAKQalnJycoFzowE9fu3bt8s60tbV5Z/Lz870zktTR0eGdqaio8M5MmzbNO9PY2OidCXXdddd5Z+rr670z119/vXcmLy/POyNJDz74oHemoaEh6FgMMAUADGiUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADPDrRcAZEJ/DocvLCz0zpSXl3tn/vGPf3hnRowY4Z2Rzk2z93Xw4EHvzPvvv++d+dOf/uSd+fTTT70zkvTkk096Zw4dOuSdaWlp8c5caTr1pRw7diwolyncCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADDDAFMMSj09Pf12rIcfftg7c/LkSe/MsGH+f2fs7u72zkhhQ1nb29u9M/v37/fOzJkzxzszZswY74wkffTRR96Zzs5O70wsFvPO5OXleWckacKECd6Zffv2BR3ranAnBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwDTIFr9Mwzz3hnEomEd6agoMA7c/bsWe+MJEUiEe/MyJEj++U4zc3N3hnnnHdGkk6dOuWdCRksGjJodsSIEd4ZSZoxY4Z35u233w461tXgTggAYIYSAgCY8S6h7du3a+7cuSotLVUkEtGmTZv6PO+c08qVK1VaWqq8vDxVVFRk9GdRAACyl3cJnT59WlOmTNHatWsv+vzq1au1Zs0arV27Vrt371Y8Htc999yjtra2a14sAGBw8X5jQlVVlaqqqi76nHNOL7zwgpYvX6758+dLktavX6/i4mJt2LBBjz322LWtFgAwqKT1NaGmpia1tLSosrKy97FoNKo777xTO3fuvGgmlUopmUz22QAAQ0NaS6ilpUWSVFxc3Ofx4uLi3ufOV1tbq1gs1ruF/PxzAEB2ysi7485/779z7pKfB1i2bJkSiUTvFvIZAABAdkrrh1Xj8bikc3dEJSUlvY+3trZecHf0uWg0qmg0ms5lAACyRFrvhMrLyxWPx1VXV9f7WGdnpxoaGjRz5sx0HgoAMAh43wmdOnVKBw8e7P26qalJH3zwgQoLC3XDDTeopqZGq1at0sSJEzVx4kStWrVKo0aN0iOPPJLWhQMAsp93Cb3//vuaPXt279dLly6VJFVXV+t3v/udnn76aXV0dOiJJ57QiRMnNH36dL3zzjvKz89P36oBAINCxIVO9suQZDKpWCxmvQwMICFDLkMv6y996UvemaamJu/Mnj17vDMhA0Lb29u9M1LYEM7c3FzvTMiA1eHD/V/KDlmbJH322WfemZDBoiG/ptLSUu+MJH344YfemXvvvTfoWIlE4oqDd5kdBwAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwk9afrApcSch05lQq5Z0JnaK9YsUK78x//vMf70xbW5t3JicnxzszbFjY3zNDc75CpkeHZE6dOuWdkfpvInbI90Xor6mioiIolyncCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADDDAFMEi0Qi3pmOjo4MrORCc+fODcotXLjQO3Pw4EHvTEFBgXfm7Nmz3pmQ3yNJ6unp6ZdMyKDUM2fOeGdChuBK0qhRo7wzIUNPQ5w4cSIo9+Uvf9k7c++993rt39XVpXffffeq9uVOCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgJkhPcA0dLhjSC70WL5Chkg654KOFZrztWzZMu/MM888E3Ssjz/+2DuTm5vrncnJyfHOhAzhDFmbFDZYNMTw4f5/BPXnINfu7m7vTFdXl3cmZH2h338hQ4SnTJnitX8qlWKAKQBg4KOEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGBmSA8wHeiDOwe6b37zm96Z1atXe2e+8pWveGf+/ve/e2eksIGVIdra2rwzIcNI8/LyvDNS2BDOkO+LkIG7IZmQQamSNGLECO9Me3u7dyZkfSFrk8IGmBYWFnrtf+bMmavelzshAIAZSggAYMa7hLZv3665c+eqtLRUkUhEmzZt6vP8woULFYlE+mwzZsxI13oBAIOIdwmdPn1aU6ZM0dq1ay+5z5w5c3T06NHebfPmzde0SADA4OT9alhVVZWqqqouu080GlU8Hg9eFABgaMjIa0L19fUqKirSTTfdpEcffVStra2X3DeVSimZTPbZAABDQ9pLqKqqSq+++qq2bt2q559/Xrt379Zdd92lVCp10f1ra2sVi8V6twkTJqR7SQCAASrtnxNasGBB739PmjRJ06ZNU1lZmd566y3Nnz//gv2XLVumpUuX9n6dTCYpIgAYIjL+YdWSkhKVlZXpwIEDF30+Go0qGo1mehkAgAEo458TOn78uJqbm1VSUpLpQwEAsoz3ndCpU6d08ODB3q+bmpr0wQcfqLCwUIWFhVq5cqUefPBBlZSU6JNPPtEPf/hDjR07Vg888EBaFw4AyH7eJfT+++9r9uzZvV9//npOdXW1XnrpJe3du1evvPKKTp48qZKSEs2ePVsbN25Ufn5++lYNABgUvEuooqLisoMKt2zZck0LGqyuv/5678zdd9/tnfn617/unbnvvvu8M9K5N574+uc//+md2b17t3cmdGBlyMDPs2fPemcikYh3pj/l5OR4Z/pr+Ovp06e9M6GvO4f8mkIynZ2d3pmQgbZS2OBT3/X57M/sOACAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAmYz/ZNX+UlFR4Z350Y9+FHSskB8/XlRU5J357LPPvDMhPzIjZCqxJO3YscM7c7kJ7JcSMvU35DhS2ETsMWPGeGf6Y5KxJLW1tXlnpLAp5CGTtzs6Orwzw4b5/925p6fHOyNJJ0+e9M6EnIeQ8x36awq5Xt977z2v/X2+j7gTAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYCbiQic9ZkgymVQsFtO4ceO8BhVu27bN+1ghwyql8IGfvrq7u70zubm53pmQwZiS9IUvfME7097eHnQsXyFDLiUpEol4Z6LRqHcmlUp5Z0Kv1xBdXV3emZA/SkIGrIYMf43H494ZKex7MOT3dtSoUd6ZkSNHemckqbS01DvjO4DZOaf29nYlEgkVFBRcdl/uhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJgZbr2AS/ne977nNaAvZKhhMpn0zkhSXl6edyZkuGNPT493JmQg5OjRo70zUtj6QgY1hggZwCmFDazs6OjwzoSsL2RgZU5OjndGChvSG/I9OH78eO9MyDDSf//7394ZSTpy5Ih35r///a93JuTPopDvP0m67rrrvDOZHNrMnRAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzA3aAaXd3t9eQxzFjxngfI2TwpCR1dnZ6Z0KGT4YMKAwZRhqJRLwzUtj6UqlUv2RCBpFKYQM/Q47VX9dDNBr1zkhhg0ULCgq8M/X19d6ZZ5991jszZ84c70yokOG0Iddd6ODh66+/PiiXKdwJAQDMUEIAADNeJVRbW6tbb71V+fn5Kioq0rx587R///4++zjntHLlSpWWliovL08VFRXat29fWhcNABgcvEqooaFBixYt0q5du1RXV6euri5VVlb2+YFHq1ev1po1a7R27Vrt3r1b8Xhc99xzT9APWwMADG5eb0x4++23+3y9bt06FRUVqbGxUbNmzZJzTi+88IKWL1+u+fPnS5LWr1+v4uJibdiwQY899lj6Vg4AyHrX9JpQIpGQJBUWFkqSmpqa1NLSosrKyt59otGo7rzzTu3cufOi/49UKqVkMtlnAwAMDcEl5JzT0qVLdfvtt2vSpEmSpJaWFklScXFxn32Li4t7nztfbW2tYrFY7zZhwoTQJQEAskxwCS1evFgffvih/vCHP1zw3PmfO3HOXfKzKMuWLVMikejdmpubQ5cEAMgyQR9WXbJkid58801t3769z4fa4vG4pHN3RCUlJb2Pt7a2XnB39LloNBr8gToAQHbzuhNyzmnx4sV67bXXtHXrVpWXl/d5vry8XPF4XHV1db2PdXZ2qqGhQTNnzkzPigEAg4bXndCiRYu0YcMGvfHGG8rPz+99nScWiykvL0+RSEQ1NTVatWqVJk6cqIkTJ2rVqlUaNWqUHnnkkYz8AgAA2curhF566SVJUkVFRZ/H161bp4ULF0qSnn76aXV0dOiJJ57QiRMnNH36dL3zzjvKz89Py4IBAINHxDnnrBfxv5LJpGKxmHful7/8pXdm9uzZ3hnp/9+S7iPkrechAyvb29u9M2fPnvXOSGFDOEOGffbnJRpyLkJ+n0L+UhYyeDJkbZL085//3DvzwgsvBB2rP2zZsiUod/ToUe9MyEDgkKHIIUObJWnixInemWnTpgUdK5FIXHGwLbPjAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmBs0U7RC5ublBuZqaGu/Md7/7Xe9MaWmpdyZkwvepU6e8M6G5kGnBHR0d3pnhw4N+aHDQT/n9358ufLVCpp3/9Kc/9c7U1tZ6ZwajkGnYknTixAnvTMik+FGjRnlnjh075p2Rwv5cufHGG732d87p7NmzTNEGAAxslBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzAyaAabDhvn3aU9Pj3dmoJs9e7Z3ZurUqUHHmjRpknemrKzMO3Pdddd5Z0KlUinvzKZNm7wzzz33nHdmoBvI34PV1dVBuZBBsyFDekOGAZ88edI7I0mNjY1BuRAMMAUADGiUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMDJoBpgCAgYUBpgCAAY0SAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGa8Sqi2tla33nqr8vPzVVRUpHnz5mn//v199lm4cKEikUifbcaMGWldNABgcPAqoYaGBi1atEi7du1SXV2durq6VFlZqdOnT/fZb86cOTp69Gjvtnnz5rQuGgAwOAz32fntt9/u8/W6detUVFSkxsZGzZo1q/fxaDSqeDyenhUCAAata3pNKJFISJIKCwv7PF5fX6+ioiLddNNNevTRR9Xa2nrJ/0cqlVIymeyzAQCGhohzzoUEnXO6//77deLECe3YsaP38Y0bN2rMmDEqKytTU1OTnn32WXV1damxsVHRaPSC/8/KlSv14x//OPxXAAAYkBKJhAoKCi6/kwv0xBNPuLKyMtfc3HzZ/Y4cOeJyc3Pdn//854s+f+bMGZdIJHq35uZmJ4mNjY2NLcu3RCJxxS7xek3oc0uWLNGbb76p7du3a/z48Zfdt6SkRGVlZTpw4MBFn49Goxe9QwIADH5eJeSc05IlS/T666+rvr5e5eXlV8wcP35czc3NKikpCV4kAGBw8npjwqJFi/T73/9eGzZsUH5+vlpaWtTS0qKOjg5J0qlTp/TUU0/pvffe0yeffKL6+nrNnTtXY8eO1QMPPJCRXwAAIIv5vA6kS/y737p165xzzrW3t7vKyko3btw4l5ub62644QZXXV3tDh8+fNXHSCQS5v+OycbGxsZ27dvVvCYU/O64TEkmk4rFYtbLAABco6t5dxyz4wAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZgZcCTnnrJcAAEiDq/nzfMCVUFtbm/USAABpcDV/nkfcALv16Onp0ZEjR5Sfn69IJNLnuWQyqQkTJqi5uVkFBQVGK7THeTiH83AO5+EczsM5A+E8OOfU1tam0tJSDRt2+Xud4f20pqs2bNgwjR8//rL7FBQUDOmL7HOch3M4D+dwHs7hPJxjfR5isdhV7Tfg/jkOADB0UEIAADNZVULRaFQrVqxQNBq1XoopzsM5nIdzOA/ncB7OybbzMODemAAAGDqy6k4IADC4UEIAADOUEADADCUEADCTVSX04osvqry8XCNHjtTUqVO1Y8cO6yX1q5UrVyoSifTZ4vG49bIybvv27Zo7d65KS0sViUS0adOmPs8757Ry5UqVlpYqLy9PFRUV2rdvn81iM+hK52HhwoUXXB8zZsywWWyG1NbW6tZbb1V+fr6Kioo0b9487d+/v88+Q+F6uJrzkC3XQ9aU0MaNG1VTU6Ply5drz549uuOOO1RVVaXDhw9bL61f3XzzzTp69GjvtnfvXuslZdzp06c1ZcoUrV279qLPr169WmvWrNHatWu1e/duxeNx3XPPPYNuDuGVzoMkzZkzp8/1sXnz5n5cYeY1NDRo0aJF2rVrl+rq6tTV1aXKykqdPn26d5+hcD1czXmQsuR6cFniG9/4hnv88cf7PPbVr37V/eAHPzBaUf9bsWKFmzJlivUyTElyr7/+eu/XPT09Lh6Pu+eee673sTNnzrhYLOZ+/etfG6ywf5x/Hpxzrrq62t1///0m67HS2trqJLmGhgbn3NC9Hs4/D85lz/WQFXdCnZ2damxsVGVlZZ/HKysrtXPnTqNV2Thw4IBKS0tVXl6uhx56SIcOHbJekqmmpia1tLT0uTai0ajuvPPOIXdtSFJ9fb2Kiop000036dFHH1Vra6v1kjIqkUhIkgoLCyUN3evh/PPwuWy4HrKihI4dO6bu7m4VFxf3eby4uFgtLS1Gq+p/06dP1yuvvKItW7bo5ZdfVktLi2bOnKnjx49bL83M57//Q/3akKSqqiq9+uqr2rp1q55//nnt3r1bd911l1KplPXSMsI5p6VLl+r222/XpEmTJA3N6+Fi50HKnuthwE3Rvpzzf7SDc+6Cxwazqqqq3v+ePHmybrvtNt14441av369li5dargye0P92pCkBQsW9P73pEmTNG3aNJWVlemtt97S/PnzDVeWGYsXL9aHH36ov/71rxc8N5Suh0udh2y5HrLiTmjs2LHKycm54G8yra2tF/yNZygZPXq0Jk+erAMHDlgvxczn7w7k2rhQSUmJysrKBuX1sWTJEr355pvatm1bnx/9MtSuh0udh4sZqNdDVpTQiBEjNHXqVNXV1fV5vK6uTjNnzjRalb1UKqWPP/5YJSUl1ksxU15erng83ufa6OzsVENDw5C+NiTp+PHjam5uHlTXh3NOixcv1muvvaatW7eqvLy8z/ND5Xq40nm4mAF7PRi+KcLLH//4R5ebm+t++9vfuo8++sjV1NS40aNHu08++cR6af3mySefdPX19e7QoUNu165d7r777nP5+fmD/hy0tbW5PXv2uD179jhJbs2aNW7Pnj3u008/dc4599xzz7lYLOZee+01t3fvXvfwww+7kpISl0wmjVeeXpc7D21tbe7JJ590O3fudE1NTW7btm3utttuc1/84hcH1Xn4/ve/72KxmKuvr3dHjx7t3drb23v3GQrXw5XOQzZdD1lTQs4596tf/cqVlZW5ESNGuFtuuaXP2xGHggULFriSkhKXm5vrSktL3fz5892+ffusl5Vx27Ztc5Iu2Kqrq51z596Wu2LFChePx100GnWzZs1ye/futV10BlzuPLS3t7vKyko3btw4l5ub62644QZXXV3tDh8+bL3stLrYr1+SW7duXe8+Q+F6uNJ5yKbrgR/lAAAwkxWvCQEABidKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABm/g8a9XgMYuFCdQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "img, label = ds_train[15]\n",
    "img = img.squeeze()\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an image of an ankle boot. Now we feed this into our network. Will it identify the picture as an ankle boot? `ds_test[15]` picks the 15th item but there are two elements, the image as the first element (`[0]`) and the label as the second element (`[1]`). So `ds_test[15][0]` picks the image only as we feed it into `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0998, 0.0984, 0.1002, 0.0960, 0.1046, 0.0995, 0.1004, 0.1011, 0.1008,\n",
      "         0.0992]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logits = model(ds_test[15][0])\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "print(pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is basically as for the random image. All labels have a probability around 10%. Why is that. Well, so far we only initiated a network architecture (which includes some random model coefficients). The network has not seen any data yet which it could use to optimise the parameters such that it recognises an ankle boot.\n",
    "\n",
    "In fact you can see what the parameters for the model are (as we initialised it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0297,  0.0263,  0.0138,  ..., -0.0131,  0.0120, -0.0164],\n",
      "        [ 0.0346, -0.0287,  0.0091,  ..., -0.0123,  0.0311, -0.0298]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0228, -0.0062], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0220,  0.0044,  0.0110,  ..., -0.0281,  0.0192,  0.0105],\n",
      "        [ 0.0386,  0.0081,  0.0199,  ..., -0.0146,  0.0272,  0.0065]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0435, 0.0289], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0065, -0.0235, -0.0108,  ...,  0.0063,  0.0213,  0.0227],\n",
      "        [ 0.0048,  0.0346, -0.0352,  ..., -0.0381, -0.0037, -0.0251]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0425, -0.0273], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact there are an awful lot of parameters: $(784*512)+ 512+(512*512)+512+(512*10)+10 =669,706$. Almost $700,000$ parameters. The number is a result of the model architecture we defined as we defined the `NeuralNetwork` class. Let us look at a graphical representation of what we build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with an image that is represented by 784 pieces of information, say $X_i$ for $i = 1,..., 784. (#0)\n",
    "\n",
    "Each of the units in the first hidden layer (#1) represents a linear combination of these 784 pieces of information into a unit in the first hidden layer, think, $Lin^{(1)}_k=\\sum^{784}_{i=1}\\omega^{(1)}_{ki}X_i$ for the $k$ th of these units. That means that into each of these units we have 784 values and a parameter for each, and then you find 512 units. \n",
    "\n",
    "Each of these units you can think of as a function which combines the linear combination of all the image information ($Lin^{(1)}_k$) into an output $Lout^{(1)}_k=g(\\omega^{(1)}_{k0}+Lin^{(1)}_k)$. This requires another parameter for each unit $k$, $\\omega^{(1)}_{k0}$ and a function $g()$. In the setup we set this function to be a rectified linear activation function (`nn.ReLU()`). This is an extremely simple function of the form $g(x)=max(0,x)$.\n",
    "\n",
    "The 2nd hidden layer (#2) functions very much in the same manner. All inputs (= all outputs from the previous layer) are linearily combined into the input for the $k$th unit in the second layer, $Lin^{(2)}_k=\\sum^{512}_{i=1}\\omega^{(2)}_{ki}Lout^{(1)}_i$. This implies that there are $512*512$ parameters ($\\omega^{(2)}_{ki}$) at this stage. Again, as we specified in our class definition, the function that combines these into an output for unit $k$ is `nn.ReLU()`, $Lout^{(2)}_k=g(\\omega^{(2)}_{k0}+Lin^{(2)}_k)$. This requires 512 additional parameters, $\\omega^{(2)}_{k0}$.\n",
    "\n",
    "Finally, layer #3 defines the model outputs. Here we have 10, as specified in the class setup (`nn.Linear(512, 10)`). Each of these is a linear combination of the 512 outputs from layer 2, $Y_k=\\sum^{512}_{i=1}\\omega^{(o)}_{ki}Lout^{(2)}_i$. As we have 10 such outputs, this delivers $10*512$ additional parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NeuralNetwork Structure](images/NNstructure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have almost $700,000$ parameters and initially they are all chosen to take some random values. We shouldn't be surprised that the model was unable to distinguish an ankle boot from a t-shirt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate/Optimise/Train the model\n",
    "\n",
    "We now turn attention to the model optimisation. An econometrician would call this parameter estimation, in data science this is typically called the training o fthe model.\n",
    "\n",
    "Recall that earlier, we initiated an instance of our neural network, `model`, by calling the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any code after that line was just for illustration purposes of the networks working. So let's go back to the stage where we just initiated `model`. As discussed before the model will have been initiated with some random parameters.\n",
    "\n",
    "In order to find the best parameters that allow the model to differentiate an ankle boot from a t-shirt we will need to feed the network some data, we call this this the training data set, `ds_train`, for which we know what categories of items they are. The parameters are adjusted to keep improving the model's categorisation of these data. This is a nonlinear optimisation process, in other words it is an iterative process which potentially never ends. \n",
    "\n",
    "To make this a feasible process we have to give Python (or better `torch`) a few instructions for this process. These instructions come in the form of what is commonly called hyperparameters. Typical hyperparameters are\n",
    "\n",
    "* Number of epochs, or number of parameter improvement iterations \n",
    "* Batch size, this tells torch how many pictures to feed into the model in order to find the next improvement\n",
    "* Learning rate, this instructs torch how quickly to update parameters\n",
    "\n",
    "We adopt the same values chosen in the Torch tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing these differently will give you slightly different results. However, in the end, the idea is that these should be chosen such that the results are not sensitive to sensible changes in tehse parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some further choices to be made, namely the loss function and the algorithm.\n",
    "\n",
    "### Loss function\n",
    "\n",
    "As econometricians we are familiar with loss functions like the residual sum of squares (which we aim to minimise) or the (log-)likelihood function (which we aim to maximise). Both of these are available to users. Here however we use a different loss function called the `nn.CrossEntropyLoss`. In effect we are comparing distributions. The real outcome, say of our test ankle boot is a 1x10 vector of values with all but the last element being a 0, the last being equal to 1. Think of this as a discrete distribution.\n",
    "\n",
    "As you have seen, the output of the neural network we build is also a 1x10 vector of probabilities. Ideally we wish that the network predicts the right label (high probability on ankle boot and close to 0 probability for the other labels). Therefore, the closer the output vector is to the input label vector, the better our model does. \n",
    "\n",
    "The `nn.CrossEntropyLoss` loss function can be used to compare such vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation algorithm\n",
    "\n",
    "The process of updating the parameters (`model.parameters()`) to improve the model is an iterative one. The learning rate is one of the hyperparameters listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305326  [   64/60000]\n",
      "loss: 2.289036  [ 6464/60000]\n",
      "loss: 2.276953  [12864/60000]\n",
      "loss: 2.262890  [19264/60000]\n",
      "loss: 2.240948  [25664/60000]\n",
      "loss: 2.242036  [32064/60000]\n",
      "loss: 2.212817  [38464/60000]\n",
      "loss: 2.213861  [44864/60000]\n",
      "loss: 2.186198  [51264/60000]\n",
      "loss: 2.193768  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 2.170360 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.185197  [   64/60000]\n",
      "loss: 2.175004  [ 6464/60000]\n",
      "loss: 2.135464  [12864/60000]\n",
      "loss: 2.087795  [19264/60000]\n",
      "loss: 2.104789  [25664/60000]\n",
      "loss: 2.035072  [32064/60000]\n",
      "loss: 2.047997  [38464/60000]\n",
      "loss: 2.015226  [44864/60000]\n",
      "loss: 1.998038  [51264/60000]\n",
      "loss: 1.913921  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 1.931528 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.916316  [   64/60000]\n",
      "loss: 1.928624  [ 6464/60000]\n",
      "loss: 1.850737  [12864/60000]\n",
      "loss: 1.855171  [19264/60000]\n",
      "loss: 1.834798  [25664/60000]\n",
      "loss: 1.744976  [32064/60000]\n",
      "loss: 1.686930  [38464/60000]\n",
      "loss: 1.641059  [44864/60000]\n",
      "loss: 1.656805  [51264/60000]\n",
      "loss: 1.564776  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.571803 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.534739  [   64/60000]\n",
      "loss: 1.531053  [ 6464/60000]\n",
      "loss: 1.525390  [12864/60000]\n",
      "loss: 1.468488  [19264/60000]\n",
      "loss: 1.406947  [25664/60000]\n",
      "loss: 1.349014  [32064/60000]\n",
      "loss: 1.438531  [38464/60000]\n",
      "loss: 1.307468  [44864/60000]\n",
      "loss: 1.394831  [51264/60000]\n",
      "loss: 1.175969  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 1.282434 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.188197  [   64/60000]\n",
      "loss: 1.318095  [ 6464/60000]\n",
      "loss: 1.235144  [12864/60000]\n",
      "loss: 1.229596  [19264/60000]\n",
      "loss: 1.234889  [25664/60000]\n",
      "loss: 1.174535  [32064/60000]\n",
      "loss: 1.084742  [38464/60000]\n",
      "loss: 0.994616  [44864/60000]\n",
      "loss: 1.162681  [51264/60000]\n",
      "loss: 1.150312  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 1.101014 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.027814  [   64/60000]\n",
      "loss: 1.000091  [ 6464/60000]\n",
      "loss: 0.990814  [12864/60000]\n",
      "loss: 0.983009  [19264/60000]\n",
      "loss: 0.955716  [25664/60000]\n",
      "loss: 0.932735  [32064/60000]\n",
      "loss: 0.861907  [38464/60000]\n",
      "loss: 1.082075  [44864/60000]\n",
      "loss: 0.978427  [51264/60000]\n",
      "loss: 0.968820  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.986072 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.833866  [   64/60000]\n",
      "loss: 1.019256  [ 6464/60000]\n",
      "loss: 0.983401  [12864/60000]\n",
      "loss: 0.881140  [19264/60000]\n",
      "loss: 0.878618  [25664/60000]\n",
      "loss: 0.989899  [32064/60000]\n",
      "loss: 0.929075  [38464/60000]\n",
      "loss: 0.892306  [44864/60000]\n",
      "loss: 0.821830  [51264/60000]\n",
      "loss: 0.946572  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.909826 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.925532  [   64/60000]\n",
      "loss: 0.990713  [ 6464/60000]\n",
      "loss: 0.828975  [12864/60000]\n",
      "loss: 0.893257  [19264/60000]\n",
      "loss: 0.900382  [25664/60000]\n",
      "loss: 0.881218  [32064/60000]\n",
      "loss: 0.872402  [38464/60000]\n",
      "loss: 0.886215  [44864/60000]\n",
      "loss: 0.707004  [51264/60000]\n",
      "loss: 0.810526  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.857960 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.899855  [   64/60000]\n",
      "loss: 0.845958  [ 6464/60000]\n",
      "loss: 0.734564  [12864/60000]\n",
      "loss: 0.744540  [19264/60000]\n",
      "loss: 0.902694  [25664/60000]\n",
      "loss: 0.765148  [32064/60000]\n",
      "loss: 0.662695  [38464/60000]\n",
      "loss: 0.900506  [44864/60000]\n",
      "loss: 0.693988  [51264/60000]\n",
      "loss: 0.784510  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.818502 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.004526  [   64/60000]\n",
      "loss: 0.813088  [ 6464/60000]\n",
      "loss: 0.801409  [12864/60000]\n",
      "loss: 0.758419  [19264/60000]\n",
      "loss: 0.823173  [25664/60000]\n",
      "loss: 0.771755  [32064/60000]\n",
      "loss: 0.717861  [38464/60000]\n",
      "loss: 0.918349  [44864/60000]\n",
      "loss: 0.839937  [51264/60000]\n",
      "loss: 0.678205  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.789382 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.847093  [   64/60000]\n",
      "loss: 0.745402  [ 6464/60000]\n",
      "loss: 0.760830  [12864/60000]\n",
      "loss: 0.890984  [19264/60000]\n",
      "loss: 0.837588  [25664/60000]\n",
      "loss: 1.135992  [32064/60000]\n",
      "loss: 0.857223  [38464/60000]\n",
      "loss: 0.993419  [44864/60000]\n",
      "loss: 0.599004  [51264/60000]\n",
      "loss: 0.722167  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.761563 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.786666  [   64/60000]\n",
      "loss: 0.699043  [ 6464/60000]\n",
      "loss: 0.822255  [12864/60000]\n",
      "loss: 0.688625  [19264/60000]\n",
      "loss: 0.626388  [25664/60000]\n",
      "loss: 0.849042  [32064/60000]\n",
      "loss: 0.790252  [38464/60000]\n",
      "loss: 0.746612  [44864/60000]\n",
      "loss: 0.739381  [51264/60000]\n",
      "loss: 0.717662  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.741126 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.901815  [   64/60000]\n",
      "loss: 0.781621  [ 6464/60000]\n",
      "loss: 0.728851  [12864/60000]\n",
      "loss: 0.618753  [19264/60000]\n",
      "loss: 0.701895  [25664/60000]\n",
      "loss: 0.637537  [32064/60000]\n",
      "loss: 0.602104  [38464/60000]\n",
      "loss: 0.834972  [44864/60000]\n",
      "loss: 0.619205  [51264/60000]\n",
      "loss: 0.677943  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.722870 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.779806  [   64/60000]\n",
      "loss: 0.643038  [ 6464/60000]\n",
      "loss: 0.635505  [12864/60000]\n",
      "loss: 0.568559  [19264/60000]\n",
      "loss: 0.598350  [25664/60000]\n",
      "loss: 0.654325  [32064/60000]\n",
      "loss: 0.746313  [38464/60000]\n",
      "loss: 0.593964  [44864/60000]\n",
      "loss: 0.815469  [51264/60000]\n",
      "loss: 0.582138  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.706043 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.733634  [   64/60000]\n",
      "loss: 0.636145  [ 6464/60000]\n",
      "loss: 0.643499  [12864/60000]\n",
      "loss: 0.638684  [19264/60000]\n",
      "loss: 0.650634  [25664/60000]\n",
      "loss: 0.649303  [32064/60000]\n",
      "loss: 0.689164  [38464/60000]\n",
      "loss: 0.495951  [44864/60000]\n",
      "loss: 0.687606  [51264/60000]\n",
      "loss: 0.540725  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.689219 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.578491  [   64/60000]\n",
      "loss: 0.588602  [ 6464/60000]\n",
      "loss: 0.557857  [12864/60000]\n",
      "loss: 0.653834  [19264/60000]\n",
      "loss: 0.620860  [25664/60000]\n",
      "loss: 0.519296  [32064/60000]\n",
      "loss: 0.648724  [38464/60000]\n",
      "loss: 0.871069  [44864/60000]\n",
      "loss: 0.616242  [51264/60000]\n",
      "loss: 0.575439  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.674667 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.810037  [   64/60000]\n",
      "loss: 1.041955  [ 6464/60000]\n",
      "loss: 0.734435  [12864/60000]\n",
      "loss: 0.658745  [19264/60000]\n",
      "loss: 0.599019  [25664/60000]\n",
      "loss: 0.704522  [32064/60000]\n",
      "loss: 0.586079  [38464/60000]\n",
      "loss: 0.576932  [44864/60000]\n",
      "loss: 0.639895  [51264/60000]\n",
      "loss: 0.633513  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.662241 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.733343  [   64/60000]\n",
      "loss: 0.618769  [ 6464/60000]\n",
      "loss: 0.525391  [12864/60000]\n",
      "loss: 0.758216  [19264/60000]\n",
      "loss: 0.695503  [25664/60000]\n",
      "loss: 0.513389  [32064/60000]\n",
      "loss: 0.624555  [38464/60000]\n",
      "loss: 0.678084  [44864/60000]\n",
      "loss: 0.945906  [51264/60000]\n",
      "loss: 0.452355  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.649673 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.554473  [   64/60000]\n",
      "loss: 0.794636  [ 6464/60000]\n",
      "loss: 0.513254  [12864/60000]\n",
      "loss: 0.637101  [19264/60000]\n",
      "loss: 0.590756  [25664/60000]\n",
      "loss: 0.540154  [32064/60000]\n",
      "loss: 0.477616  [38464/60000]\n",
      "loss: 0.731380  [44864/60000]\n",
      "loss: 0.555277  [51264/60000]\n",
      "loss: 0.706441  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.636148 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.689255  [   64/60000]\n",
      "loss: 0.646484  [ 6464/60000]\n",
      "loss: 0.632523  [12864/60000]\n",
      "loss: 0.546836  [19264/60000]\n",
      "loss: 0.848497  [25664/60000]\n",
      "loss: 0.577244  [32064/60000]\n",
      "loss: 0.559701  [38464/60000]\n",
      "loss: 0.552564  [44864/60000]\n",
      "loss: 0.393794  [51264/60000]\n",
      "loss: 0.518873  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.626961 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.674781  [   64/60000]\n",
      "loss: 0.726765  [ 6464/60000]\n",
      "loss: 0.424264  [12864/60000]\n",
      "loss: 0.594188  [19264/60000]\n",
      "loss: 0.672536  [25664/60000]\n",
      "loss: 0.570045  [32064/60000]\n",
      "loss: 0.422466  [38464/60000]\n",
      "loss: 0.548070  [44864/60000]\n",
      "loss: 0.819756  [51264/60000]\n",
      "loss: 0.609603  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.615202 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.770761  [   64/60000]\n",
      "loss: 0.574818  [ 6464/60000]\n",
      "loss: 0.514253  [12864/60000]\n",
      "loss: 0.488667  [19264/60000]\n",
      "loss: 0.595395  [25664/60000]\n",
      "loss: 0.559618  [32064/60000]\n",
      "loss: 0.777944  [38464/60000]\n",
      "loss: 0.733934  [44864/60000]\n",
      "loss: 0.666128  [51264/60000]\n",
      "loss: 0.600410  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.606483 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.529946  [   64/60000]\n",
      "loss: 0.515481  [ 6464/60000]\n",
      "loss: 0.577329  [12864/60000]\n",
      "loss: 0.621101  [19264/60000]\n",
      "loss: 0.563758  [25664/60000]\n",
      "loss: 0.679722  [32064/60000]\n",
      "loss: 0.689649  [38464/60000]\n",
      "loss: 0.600990  [44864/60000]\n",
      "loss: 0.563850  [51264/60000]\n",
      "loss: 0.659927  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.599735 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.563758  [   64/60000]\n",
      "loss: 0.679116  [ 6464/60000]\n",
      "loss: 0.618499  [12864/60000]\n",
      "loss: 0.593266  [19264/60000]\n",
      "loss: 0.748057  [25664/60000]\n",
      "loss: 0.581333  [32064/60000]\n",
      "loss: 0.511673  [38464/60000]\n",
      "loss: 0.713700  [44864/60000]\n",
      "loss: 0.636341  [51264/60000]\n",
      "loss: 0.469122  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.590075 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.565298  [   64/60000]\n",
      "loss: 0.476219  [ 6464/60000]\n",
      "loss: 0.653223  [12864/60000]\n",
      "loss: 0.506639  [19264/60000]\n",
      "loss: 0.518642  [25664/60000]\n",
      "loss: 0.517833  [32064/60000]\n",
      "loss: 0.523730  [38464/60000]\n",
      "loss: 0.714312  [44864/60000]\n",
      "loss: 0.630257  [51264/60000]\n",
      "loss: 0.614193  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.583943 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.585094  [   64/60000]\n",
      "loss: 0.601482  [ 6464/60000]\n",
      "loss: 0.512507  [12864/60000]\n",
      "loss: 0.560336  [19264/60000]\n",
      "loss: 0.582824  [25664/60000]\n",
      "loss: 0.629225  [32064/60000]\n",
      "loss: 0.467158  [38464/60000]\n",
      "loss: 0.471989  [44864/60000]\n",
      "loss: 0.402653  [51264/60000]\n",
      "loss: 0.405278  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.574916 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.504993  [   64/60000]\n",
      "loss: 0.539996  [ 6464/60000]\n",
      "loss: 0.612603  [12864/60000]\n",
      "loss: 0.433509  [19264/60000]\n",
      "loss: 0.430362  [25664/60000]\n",
      "loss: 0.515201  [32064/60000]\n",
      "loss: 0.514075  [38464/60000]\n",
      "loss: 0.583366  [44864/60000]\n",
      "loss: 0.663024  [51264/60000]\n",
      "loss: 0.346962  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.567827 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.662820  [   64/60000]\n",
      "loss: 0.677741  [ 6464/60000]\n",
      "loss: 0.356815  [12864/60000]\n",
      "loss: 0.651981  [19264/60000]\n",
      "loss: 0.554415  [25664/60000]\n",
      "loss: 0.765307  [32064/60000]\n",
      "loss: 0.370017  [38464/60000]\n",
      "loss: 0.513814  [44864/60000]\n",
      "loss: 0.457710  [51264/60000]\n",
      "loss: 0.546009  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.565860 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.489683  [   64/60000]\n",
      "loss: 0.711005  [ 6464/60000]\n",
      "loss: 0.714005  [12864/60000]\n",
      "loss: 0.537713  [19264/60000]\n",
      "loss: 0.631221  [25664/60000]\n",
      "loss: 0.356562  [32064/60000]\n",
      "loss: 0.436218  [38464/60000]\n",
      "loss: 0.418943  [44864/60000]\n",
      "loss: 0.572796  [51264/60000]\n",
      "loss: 0.496954  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.557491 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.633719  [   64/60000]\n",
      "loss: 0.460849  [ 6464/60000]\n",
      "loss: 0.497683  [12864/60000]\n",
      "loss: 0.730541  [19264/60000]\n",
      "loss: 0.510101  [25664/60000]\n",
      "loss: 0.616405  [32064/60000]\n",
      "loss: 0.470335  [38464/60000]\n",
      "loss: 0.813428  [44864/60000]\n",
      "loss: 0.576177  [51264/60000]\n",
      "loss: 0.622012  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.552079 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.570885  [   64/60000]\n",
      "loss: 0.497668  [ 6464/60000]\n",
      "loss: 0.362692  [12864/60000]\n",
      "loss: 0.376972  [19264/60000]\n",
      "loss: 0.431448  [25664/60000]\n",
      "loss: 0.339088  [32064/60000]\n",
      "loss: 0.676478  [38464/60000]\n",
      "loss: 0.563016  [44864/60000]\n",
      "loss: 0.367607  [51264/60000]\n",
      "loss: 0.653668  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.548655 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.438573  [   64/60000]\n",
      "loss: 0.325972  [ 6464/60000]\n",
      "loss: 0.565655  [12864/60000]\n",
      "loss: 0.507870  [19264/60000]\n",
      "loss: 0.695854  [25664/60000]\n",
      "loss: 0.644619  [32064/60000]\n",
      "loss: 0.453732  [38464/60000]\n",
      "loss: 0.462094  [44864/60000]\n",
      "loss: 0.604535  [51264/60000]\n",
      "loss: 0.361737  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.541502 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.686448  [   64/60000]\n",
      "loss: 0.358375  [ 6464/60000]\n",
      "loss: 0.576995  [12864/60000]\n",
      "loss: 0.481212  [19264/60000]\n",
      "loss: 0.480235  [25664/60000]\n",
      "loss: 0.556946  [32064/60000]\n",
      "loss: 0.664907  [38464/60000]\n",
      "loss: 0.444182  [44864/60000]\n",
      "loss: 0.556072  [51264/60000]\n",
      "loss: 0.418416  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.535855 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.575218  [   64/60000]\n",
      "loss: 0.394729  [ 6464/60000]\n",
      "loss: 0.596435  [12864/60000]\n",
      "loss: 0.416936  [19264/60000]\n",
      "loss: 0.435068  [25664/60000]\n",
      "loss: 0.533186  [32064/60000]\n",
      "loss: 0.332152  [38464/60000]\n",
      "loss: 0.329301  [44864/60000]\n",
      "loss: 0.618731  [51264/60000]\n",
      "loss: 0.424186  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.533391 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.334029  [   64/60000]\n",
      "loss: 0.557830  [ 6464/60000]\n",
      "loss: 0.406576  [12864/60000]\n",
      "loss: 0.358363  [19264/60000]\n",
      "loss: 0.544554  [25664/60000]\n",
      "loss: 0.421427  [32064/60000]\n",
      "loss: 0.455877  [38464/60000]\n",
      "loss: 0.524853  [44864/60000]\n",
      "loss: 0.560428  [51264/60000]\n",
      "loss: 0.487665  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.532095 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.476809  [   64/60000]\n",
      "loss: 0.552603  [ 6464/60000]\n",
      "loss: 0.365315  [12864/60000]\n",
      "loss: 0.719099  [19264/60000]\n",
      "loss: 0.541987  [25664/60000]\n",
      "loss: 0.562838  [32064/60000]\n",
      "loss: 0.326803  [38464/60000]\n",
      "loss: 0.651814  [44864/60000]\n",
      "loss: 0.358137  [51264/60000]\n",
      "loss: 0.482769  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.525338 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.397810  [   64/60000]\n",
      "loss: 0.653855  [ 6464/60000]\n",
      "loss: 0.599154  [12864/60000]\n",
      "loss: 0.513365  [19264/60000]\n",
      "loss: 0.670339  [25664/60000]\n",
      "loss: 0.448934  [32064/60000]\n",
      "loss: 0.413366  [38464/60000]\n",
      "loss: 0.489701  [44864/60000]\n",
      "loss: 0.522280  [51264/60000]\n",
      "loss: 0.439866  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.522482 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.393871  [   64/60000]\n",
      "loss: 0.474157  [ 6464/60000]\n",
      "loss: 0.436562  [12864/60000]\n",
      "loss: 0.629095  [19264/60000]\n",
      "loss: 0.308736  [25664/60000]\n",
      "loss: 0.536118  [32064/60000]\n",
      "loss: 0.508462  [38464/60000]\n",
      "loss: 0.468355  [44864/60000]\n",
      "loss: 0.359017  [51264/60000]\n",
      "loss: 0.477759  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.521016 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.573992  [   64/60000]\n",
      "loss: 0.343999  [ 6464/60000]\n",
      "loss: 0.520107  [12864/60000]\n",
      "loss: 0.558105  [19264/60000]\n",
      "loss: 0.595379  [25664/60000]\n",
      "loss: 0.469577  [32064/60000]\n",
      "loss: 0.621111  [38464/60000]\n",
      "loss: 0.443497  [44864/60000]\n",
      "loss: 0.463184  [51264/60000]\n",
      "loss: 0.701454  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.517339 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.436444  [   64/60000]\n",
      "loss: 0.499724  [ 6464/60000]\n",
      "loss: 0.299056  [12864/60000]\n",
      "loss: 0.465718  [19264/60000]\n",
      "loss: 0.657888  [25664/60000]\n",
      "loss: 0.587519  [32064/60000]\n",
      "loss: 0.526006  [38464/60000]\n",
      "loss: 0.500691  [44864/60000]\n",
      "loss: 0.545336  [51264/60000]\n",
      "loss: 0.396304  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.513621 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.313912  [   64/60000]\n",
      "loss: 0.349058  [ 6464/60000]\n",
      "loss: 0.433650  [12864/60000]\n",
      "loss: 0.591390  [19264/60000]\n",
      "loss: 0.398089  [25664/60000]\n",
      "loss: 0.490372  [32064/60000]\n",
      "loss: 0.411168  [38464/60000]\n",
      "loss: 0.434250  [44864/60000]\n",
      "loss: 0.860213  [51264/60000]\n",
      "loss: 0.447609  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.510262 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.432018  [   64/60000]\n",
      "loss: 0.412437  [ 6464/60000]\n",
      "loss: 0.490105  [12864/60000]\n",
      "loss: 0.331960  [19264/60000]\n",
      "loss: 0.712305  [25664/60000]\n",
      "loss: 0.387334  [32064/60000]\n",
      "loss: 0.449822  [38464/60000]\n",
      "loss: 0.425031  [44864/60000]\n",
      "loss: 0.495417  [51264/60000]\n",
      "loss: 0.372057  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.506476 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.376386  [   64/60000]\n",
      "loss: 0.376275  [ 6464/60000]\n",
      "loss: 0.398384  [12864/60000]\n",
      "loss: 0.567333  [19264/60000]\n",
      "loss: 0.737985  [25664/60000]\n",
      "loss: 0.408425  [32064/60000]\n",
      "loss: 0.342632  [38464/60000]\n",
      "loss: 0.500586  [44864/60000]\n",
      "loss: 0.474488  [51264/60000]\n",
      "loss: 0.486561  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.506146 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.426576  [   64/60000]\n",
      "loss: 0.656407  [ 6464/60000]\n",
      "loss: 0.522805  [12864/60000]\n",
      "loss: 0.441520  [19264/60000]\n",
      "loss: 0.351094  [25664/60000]\n",
      "loss: 0.399060  [32064/60000]\n",
      "loss: 0.483335  [38464/60000]\n",
      "loss: 0.413700  [44864/60000]\n",
      "loss: 0.699819  [51264/60000]\n",
      "loss: 0.394045  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.504328 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.411861  [   64/60000]\n",
      "loss: 0.596543  [ 6464/60000]\n",
      "loss: 0.463057  [12864/60000]\n",
      "loss: 0.356990  [19264/60000]\n",
      "loss: 0.401779  [25664/60000]\n",
      "loss: 0.638618  [32064/60000]\n",
      "loss: 0.351482  [38464/60000]\n",
      "loss: 0.377106  [44864/60000]\n",
      "loss: 0.330660  [51264/60000]\n",
      "loss: 0.399273  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.499990 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.433145  [   64/60000]\n",
      "loss: 0.472320  [ 6464/60000]\n",
      "loss: 0.542851  [12864/60000]\n",
      "loss: 0.664099  [19264/60000]\n",
      "loss: 0.365835  [25664/60000]\n",
      "loss: 0.400898  [32064/60000]\n",
      "loss: 0.399669  [38464/60000]\n",
      "loss: 0.503519  [44864/60000]\n",
      "loss: 0.314512  [51264/60000]\n",
      "loss: 0.297096  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.499431 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.598314  [   64/60000]\n",
      "loss: 0.531140  [ 6464/60000]\n",
      "loss: 0.364166  [12864/60000]\n",
      "loss: 0.618342  [19264/60000]\n",
      "loss: 0.572757  [25664/60000]\n",
      "loss: 0.397794  [32064/60000]\n",
      "loss: 0.384590  [38464/60000]\n",
      "loss: 0.421750  [44864/60000]\n",
      "loss: 0.339960  [51264/60000]\n",
      "loss: 0.426664  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.500935 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.438944  [   64/60000]\n",
      "loss: 0.502520  [ 6464/60000]\n",
      "loss: 0.365380  [12864/60000]\n",
      "loss: 0.466276  [19264/60000]\n",
      "loss: 0.516707  [25664/60000]\n",
      "loss: 0.608161  [32064/60000]\n",
      "loss: 0.472865  [38464/60000]\n",
      "loss: 0.452361  [44864/60000]\n",
      "loss: 0.315018  [51264/60000]\n",
      "loss: 0.390933  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.494185 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.307946  [   64/60000]\n",
      "loss: 0.479370  [ 6464/60000]\n",
      "loss: 0.360551  [12864/60000]\n",
      "loss: 0.418000  [19264/60000]\n",
      "loss: 0.553047  [25664/60000]\n",
      "loss: 0.581512  [32064/60000]\n",
      "loss: 0.435124  [38464/60000]\n",
      "loss: 0.457437  [44864/60000]\n",
      "loss: 0.431862  [51264/60000]\n",
      "loss: 0.603967  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.492256 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.280981  [   64/60000]\n",
      "loss: 0.506792  [ 6464/60000]\n",
      "loss: 0.551267  [12864/60000]\n",
      "loss: 0.509847  [19264/60000]\n",
      "loss: 0.377793  [25664/60000]\n",
      "loss: 0.481132  [32064/60000]\n",
      "loss: 0.508422  [38464/60000]\n",
      "loss: 0.401348  [44864/60000]\n",
      "loss: 0.843980  [51264/60000]\n",
      "loss: 0.406212  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.490883 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.382560  [   64/60000]\n",
      "loss: 0.618537  [ 6464/60000]\n",
      "loss: 0.425437  [12864/60000]\n",
      "loss: 0.253640  [19264/60000]\n",
      "loss: 0.419895  [25664/60000]\n",
      "loss: 0.845419  [32064/60000]\n",
      "loss: 0.461365  [38464/60000]\n",
      "loss: 0.500817  [44864/60000]\n",
      "loss: 0.475627  [51264/60000]\n",
      "loss: 0.441467  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.491305 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.412262  [   64/60000]\n",
      "loss: 0.465777  [ 6464/60000]\n",
      "loss: 0.465971  [12864/60000]\n",
      "loss: 0.605554  [19264/60000]\n",
      "loss: 0.308452  [25664/60000]\n",
      "loss: 0.524090  [32064/60000]\n",
      "loss: 0.489352  [38464/60000]\n",
      "loss: 0.406680  [44864/60000]\n",
      "loss: 0.462777  [51264/60000]\n",
      "loss: 0.358613  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.489496 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.420583  [   64/60000]\n",
      "loss: 0.527346  [ 6464/60000]\n",
      "loss: 0.471339  [12864/60000]\n",
      "loss: 0.422064  [19264/60000]\n",
      "loss: 0.517365  [25664/60000]\n",
      "loss: 0.325773  [32064/60000]\n",
      "loss: 0.553999  [38464/60000]\n",
      "loss: 0.602301  [44864/60000]\n",
      "loss: 0.498264  [51264/60000]\n",
      "loss: 0.536011  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.485995 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.454266  [   64/60000]\n",
      "loss: 0.522276  [ 6464/60000]\n",
      "loss: 0.462406  [12864/60000]\n",
      "loss: 0.348099  [19264/60000]\n",
      "loss: 0.439925  [25664/60000]\n",
      "loss: 0.292964  [32064/60000]\n",
      "loss: 0.546202  [38464/60000]\n",
      "loss: 0.406998  [44864/60000]\n",
      "loss: 0.308872  [51264/60000]\n",
      "loss: 0.573307  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.485645 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.352258  [   64/60000]\n",
      "loss: 0.565688  [ 6464/60000]\n",
      "loss: 0.330207  [12864/60000]\n",
      "loss: 0.427508  [19264/60000]\n",
      "loss: 0.578771  [25664/60000]\n",
      "loss: 0.618834  [32064/60000]\n",
      "loss: 0.474897  [38464/60000]\n",
      "loss: 0.640845  [44864/60000]\n",
      "loss: 0.328812  [51264/60000]\n",
      "loss: 0.273914  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.483271 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.372089  [   64/60000]\n",
      "loss: 0.401789  [ 6464/60000]\n",
      "loss: 0.457468  [12864/60000]\n",
      "loss: 0.629902  [19264/60000]\n",
      "loss: 0.502242  [25664/60000]\n",
      "loss: 0.491491  [32064/60000]\n",
      "loss: 0.570047  [38464/60000]\n",
      "loss: 0.372019  [44864/60000]\n",
      "loss: 0.523677  [51264/60000]\n",
      "loss: 0.473523  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.483632 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.599214  [   64/60000]\n",
      "loss: 0.336876  [ 6464/60000]\n",
      "loss: 0.501695  [12864/60000]\n",
      "loss: 0.572065  [19264/60000]\n",
      "loss: 0.399577  [25664/60000]\n",
      "loss: 0.448819  [32064/60000]\n",
      "loss: 0.306815  [38464/60000]\n",
      "loss: 0.487740  [44864/60000]\n",
      "loss: 0.506560  [51264/60000]\n",
      "loss: 0.410625  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.478863 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.296534  [   64/60000]\n",
      "loss: 0.343449  [ 6464/60000]\n",
      "loss: 0.567268  [12864/60000]\n",
      "loss: 0.541524  [19264/60000]\n",
      "loss: 0.339595  [25664/60000]\n",
      "loss: 0.467354  [32064/60000]\n",
      "loss: 0.234194  [38464/60000]\n",
      "loss: 0.375914  [44864/60000]\n",
      "loss: 0.586886  [51264/60000]\n",
      "loss: 0.327804  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.478856 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.443026  [   64/60000]\n",
      "loss: 0.440054  [ 6464/60000]\n",
      "loss: 0.416023  [12864/60000]\n",
      "loss: 0.399968  [19264/60000]\n",
      "loss: 0.260164  [25664/60000]\n",
      "loss: 0.473600  [32064/60000]\n",
      "loss: 0.550614  [38464/60000]\n",
      "loss: 0.594612  [44864/60000]\n",
      "loss: 0.586799  [51264/60000]\n",
      "loss: 0.330156  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.475452 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.488585  [   64/60000]\n",
      "loss: 0.403634  [ 6464/60000]\n",
      "loss: 0.427740  [12864/60000]\n",
      "loss: 0.459599  [19264/60000]\n",
      "loss: 0.483079  [25664/60000]\n",
      "loss: 0.780866  [32064/60000]\n",
      "loss: 0.545560  [38464/60000]\n",
      "loss: 0.374090  [44864/60000]\n",
      "loss: 0.562106  [51264/60000]\n",
      "loss: 0.375848  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.475360 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.547303  [   64/60000]\n",
      "loss: 0.389527  [ 6464/60000]\n",
      "loss: 0.469627  [12864/60000]\n",
      "loss: 0.328055  [19264/60000]\n",
      "loss: 0.324220  [25664/60000]\n",
      "loss: 0.484945  [32064/60000]\n",
      "loss: 0.432683  [38464/60000]\n",
      "loss: 0.723616  [44864/60000]\n",
      "loss: 0.315615  [51264/60000]\n",
      "loss: 0.394240  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.474589 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.260847  [   64/60000]\n",
      "loss: 0.485240  [ 6464/60000]\n",
      "loss: 0.424287  [12864/60000]\n",
      "loss: 0.244903  [19264/60000]\n",
      "loss: 0.309309  [25664/60000]\n",
      "loss: 0.556197  [32064/60000]\n",
      "loss: 0.439923  [38464/60000]\n",
      "loss: 0.423132  [44864/60000]\n",
      "loss: 0.405991  [51264/60000]\n",
      "loss: 0.458847  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.474282 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.471250  [   64/60000]\n",
      "loss: 0.514703  [ 6464/60000]\n",
      "loss: 0.431794  [12864/60000]\n",
      "loss: 0.545656  [19264/60000]\n",
      "loss: 0.324466  [25664/60000]\n",
      "loss: 0.341756  [32064/60000]\n",
      "loss: 0.371743  [38464/60000]\n",
      "loss: 0.381682  [44864/60000]\n",
      "loss: 0.383472  [51264/60000]\n",
      "loss: 0.438413  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.472544 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.574300  [   64/60000]\n",
      "loss: 0.419955  [ 6464/60000]\n",
      "loss: 0.378205  [12864/60000]\n",
      "loss: 0.401229  [19264/60000]\n",
      "loss: 0.349300  [25664/60000]\n",
      "loss: 0.561474  [32064/60000]\n",
      "loss: 0.425439  [38464/60000]\n",
      "loss: 0.266683  [44864/60000]\n",
      "loss: 0.536188  [51264/60000]\n",
      "loss: 0.420761  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.470687 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.636690  [   64/60000]\n",
      "loss: 0.440301  [ 6464/60000]\n",
      "loss: 0.432487  [12864/60000]\n",
      "loss: 0.647344  [19264/60000]\n",
      "loss: 0.265977  [25664/60000]\n",
      "loss: 0.357381  [32064/60000]\n",
      "loss: 0.372496  [38464/60000]\n",
      "loss: 0.430391  [44864/60000]\n",
      "loss: 0.448451  [51264/60000]\n",
      "loss: 0.432044  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.468122 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.628301  [   64/60000]\n",
      "loss: 0.485679  [ 6464/60000]\n",
      "loss: 0.328915  [12864/60000]\n",
      "loss: 0.414655  [19264/60000]\n",
      "loss: 0.502614  [25664/60000]\n",
      "loss: 0.359501  [32064/60000]\n",
      "loss: 0.301534  [38464/60000]\n",
      "loss: 0.314348  [44864/60000]\n",
      "loss: 0.357477  [51264/60000]\n",
      "loss: 0.679943  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.468936 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.394503  [   64/60000]\n",
      "loss: 0.364361  [ 6464/60000]\n",
      "loss: 0.609966  [12864/60000]\n",
      "loss: 0.332326  [19264/60000]\n",
      "loss: 0.459189  [25664/60000]\n",
      "loss: 0.701312  [32064/60000]\n",
      "loss: 0.481950  [38464/60000]\n",
      "loss: 0.450759  [44864/60000]\n",
      "loss: 0.392732  [51264/60000]\n",
      "loss: 0.245360  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.465607 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.296973  [   64/60000]\n",
      "loss: 0.372917  [ 6464/60000]\n",
      "loss: 0.432761  [12864/60000]\n",
      "loss: 0.366593  [19264/60000]\n",
      "loss: 0.496163  [25664/60000]\n",
      "loss: 0.482944  [32064/60000]\n",
      "loss: 0.437776  [38464/60000]\n",
      "loss: 0.422937  [44864/60000]\n",
      "loss: 0.309859  [51264/60000]\n",
      "loss: 0.403795  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.465965 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.617847  [   64/60000]\n",
      "loss: 0.475325  [ 6464/60000]\n",
      "loss: 0.555610  [12864/60000]\n",
      "loss: 0.476031  [19264/60000]\n",
      "loss: 0.407626  [25664/60000]\n",
      "loss: 0.293271  [32064/60000]\n",
      "loss: 0.373055  [38464/60000]\n",
      "loss: 0.512801  [44864/60000]\n",
      "loss: 0.330615  [51264/60000]\n",
      "loss: 0.475602  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.467291 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.362414  [   64/60000]\n",
      "loss: 0.383044  [ 6464/60000]\n",
      "loss: 0.280194  [12864/60000]\n",
      "loss: 0.379920  [19264/60000]\n",
      "loss: 0.347734  [25664/60000]\n",
      "loss: 0.451829  [32064/60000]\n",
      "loss: 0.391612  [38464/60000]\n",
      "loss: 0.434295  [44864/60000]\n",
      "loss: 0.348875  [51264/60000]\n",
      "loss: 0.471148  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.463251 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.390434  [   64/60000]\n",
      "loss: 0.437276  [ 6464/60000]\n",
      "loss: 0.280914  [12864/60000]\n",
      "loss: 0.419146  [19264/60000]\n",
      "loss: 0.251983  [25664/60000]\n",
      "loss: 0.388754  [32064/60000]\n",
      "loss: 0.421455  [38464/60000]\n",
      "loss: 0.474695  [44864/60000]\n",
      "loss: 0.351102  [51264/60000]\n",
      "loss: 0.559934  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.462560 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.512128  [   64/60000]\n",
      "loss: 0.481700  [ 6464/60000]\n",
      "loss: 0.482184  [12864/60000]\n",
      "loss: 0.455325  [19264/60000]\n",
      "loss: 0.317694  [25664/60000]\n",
      "loss: 0.466504  [32064/60000]\n",
      "loss: 0.449420  [38464/60000]\n",
      "loss: 0.361384  [44864/60000]\n",
      "loss: 0.479298  [51264/60000]\n",
      "loss: 0.562157  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.462265 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.467800  [   64/60000]\n",
      "loss: 0.279916  [ 6464/60000]\n",
      "loss: 0.386000  [12864/60000]\n",
      "loss: 0.410094  [19264/60000]\n",
      "loss: 0.299969  [25664/60000]\n",
      "loss: 0.456751  [32064/60000]\n",
      "loss: 0.345837  [38464/60000]\n",
      "loss: 0.463823  [44864/60000]\n",
      "loss: 0.407923  [51264/60000]\n",
      "loss: 0.389543  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.462343 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.415718  [   64/60000]\n",
      "loss: 0.306924  [ 6464/60000]\n",
      "loss: 0.327501  [12864/60000]\n",
      "loss: 0.450203  [19264/60000]\n",
      "loss: 0.701223  [25664/60000]\n",
      "loss: 0.242580  [32064/60000]\n",
      "loss: 0.321718  [38464/60000]\n",
      "loss: 0.308475  [44864/60000]\n",
      "loss: 0.496829  [51264/60000]\n",
      "loss: 0.296647  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.457343 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.357072  [   64/60000]\n",
      "loss: 0.228988  [ 6464/60000]\n",
      "loss: 0.297065  [12864/60000]\n",
      "loss: 0.378151  [19264/60000]\n",
      "loss: 0.266510  [25664/60000]\n",
      "loss: 0.396428  [32064/60000]\n",
      "loss: 0.368592  [38464/60000]\n",
      "loss: 0.394878  [44864/60000]\n",
      "loss: 0.475165  [51264/60000]\n",
      "loss: 0.373747  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.457662 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.521755  [   64/60000]\n",
      "loss: 0.490127  [ 6464/60000]\n",
      "loss: 0.261985  [12864/60000]\n",
      "loss: 0.352094  [19264/60000]\n",
      "loss: 0.525922  [25664/60000]\n",
      "loss: 0.387374  [32064/60000]\n",
      "loss: 0.414670  [38464/60000]\n",
      "loss: 0.423133  [44864/60000]\n",
      "loss: 0.602217  [51264/60000]\n",
      "loss: 0.346078  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.455295 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.372371  [   64/60000]\n",
      "loss: 0.337938  [ 6464/60000]\n",
      "loss: 0.668902  [12864/60000]\n",
      "loss: 0.429895  [19264/60000]\n",
      "loss: 0.389913  [25664/60000]\n",
      "loss: 0.354068  [32064/60000]\n",
      "loss: 0.734278  [38464/60000]\n",
      "loss: 0.575707  [44864/60000]\n",
      "loss: 0.284606  [51264/60000]\n",
      "loss: 0.393497  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.459075 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.412419  [   64/60000]\n",
      "loss: 0.386326  [ 6464/60000]\n",
      "loss: 0.365518  [12864/60000]\n",
      "loss: 0.308252  [19264/60000]\n",
      "loss: 0.446866  [25664/60000]\n",
      "loss: 0.423227  [32064/60000]\n",
      "loss: 0.306156  [38464/60000]\n",
      "loss: 0.469433  [44864/60000]\n",
      "loss: 0.294766  [51264/60000]\n",
      "loss: 0.375433  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.454409 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.258197  [   64/60000]\n",
      "loss: 0.475440  [ 6464/60000]\n",
      "loss: 0.327073  [12864/60000]\n",
      "loss: 0.368333  [19264/60000]\n",
      "loss: 0.364893  [25664/60000]\n",
      "loss: 0.367996  [32064/60000]\n",
      "loss: 0.434368  [38464/60000]\n",
      "loss: 0.327150  [44864/60000]\n",
      "loss: 0.327427  [51264/60000]\n",
      "loss: 0.256955  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.453574 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.309544  [   64/60000]\n",
      "loss: 0.382739  [ 6464/60000]\n",
      "loss: 0.347550  [12864/60000]\n",
      "loss: 0.615272  [19264/60000]\n",
      "loss: 0.332900  [25664/60000]\n",
      "loss: 0.341686  [32064/60000]\n",
      "loss: 0.451420  [38464/60000]\n",
      "loss: 0.374028  [44864/60000]\n",
      "loss: 0.416004  [51264/60000]\n",
      "loss: 0.417712  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.457415 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.434806  [   64/60000]\n",
      "loss: 0.460111  [ 6464/60000]\n",
      "loss: 0.376406  [12864/60000]\n",
      "loss: 0.496373  [19264/60000]\n",
      "loss: 0.353964  [25664/60000]\n",
      "loss: 0.355312  [32064/60000]\n",
      "loss: 0.294660  [38464/60000]\n",
      "loss: 0.347056  [44864/60000]\n",
      "loss: 0.376375  [51264/60000]\n",
      "loss: 0.629114  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.453159 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.547238  [   64/60000]\n",
      "loss: 0.486832  [ 6464/60000]\n",
      "loss: 0.649265  [12864/60000]\n",
      "loss: 0.414227  [19264/60000]\n",
      "loss: 0.520085  [25664/60000]\n",
      "loss: 0.356173  [32064/60000]\n",
      "loss: 0.337657  [38464/60000]\n",
      "loss: 0.570067  [44864/60000]\n",
      "loss: 0.508950  [51264/60000]\n",
      "loss: 0.345169  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.450389 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.474816  [   64/60000]\n",
      "loss: 0.289548  [ 6464/60000]\n",
      "loss: 0.287691  [12864/60000]\n",
      "loss: 0.364789  [19264/60000]\n",
      "loss: 0.479832  [25664/60000]\n",
      "loss: 0.279151  [32064/60000]\n",
      "loss: 0.330064  [38464/60000]\n",
      "loss: 0.387590  [44864/60000]\n",
      "loss: 0.305173  [51264/60000]\n",
      "loss: 0.496782  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.449720 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.359602  [   64/60000]\n",
      "loss: 0.513406  [ 6464/60000]\n",
      "loss: 0.425809  [12864/60000]\n",
      "loss: 0.475673  [19264/60000]\n",
      "loss: 0.395087  [25664/60000]\n",
      "loss: 0.442997  [32064/60000]\n",
      "loss: 0.381456  [38464/60000]\n",
      "loss: 0.445166  [44864/60000]\n",
      "loss: 0.553386  [51264/60000]\n",
      "loss: 0.372210  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.450732 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.308826  [   64/60000]\n",
      "loss: 0.335668  [ 6464/60000]\n",
      "loss: 0.365549  [12864/60000]\n",
      "loss: 0.554636  [19264/60000]\n",
      "loss: 0.342702  [25664/60000]\n",
      "loss: 0.765142  [32064/60000]\n",
      "loss: 0.597306  [38464/60000]\n",
      "loss: 0.610068  [44864/60000]\n",
      "loss: 0.432234  [51264/60000]\n",
      "loss: 0.601896  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.449409 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.419825  [   64/60000]\n",
      "loss: 0.380410  [ 6464/60000]\n",
      "loss: 0.328868  [12864/60000]\n",
      "loss: 0.464482  [19264/60000]\n",
      "loss: 0.290242  [25664/60000]\n",
      "loss: 0.533231  [32064/60000]\n",
      "loss: 0.436974  [38464/60000]\n",
      "loss: 0.359762  [44864/60000]\n",
      "loss: 0.371312  [51264/60000]\n",
      "loss: 0.574690  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.446565 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.354160  [   64/60000]\n",
      "loss: 0.466174  [ 6464/60000]\n",
      "loss: 0.464688  [12864/60000]\n",
      "loss: 0.544133  [19264/60000]\n",
      "loss: 0.378932  [25664/60000]\n",
      "loss: 0.515461  [32064/60000]\n",
      "loss: 0.306451  [38464/60000]\n",
      "loss: 0.471228  [44864/60000]\n",
      "loss: 0.433654  [51264/60000]\n",
      "loss: 0.492958  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.446723 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.473391  [   64/60000]\n",
      "loss: 0.617931  [ 6464/60000]\n",
      "loss: 0.415771  [12864/60000]\n",
      "loss: 0.353712  [19264/60000]\n",
      "loss: 0.342773  [25664/60000]\n",
      "loss: 0.556950  [32064/60000]\n",
      "loss: 0.428936  [38464/60000]\n",
      "loss: 0.326948  [44864/60000]\n",
      "loss: 0.400361  [51264/60000]\n",
      "loss: 0.391806  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.446054 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.325318  [   64/60000]\n",
      "loss: 0.359049  [ 6464/60000]\n",
      "loss: 0.407190  [12864/60000]\n",
      "loss: 0.319832  [19264/60000]\n",
      "loss: 0.211338  [25664/60000]\n",
      "loss: 0.239096  [32064/60000]\n",
      "loss: 0.544854  [38464/60000]\n",
      "loss: 0.444723  [44864/60000]\n",
      "loss: 0.343139  [51264/60000]\n",
      "loss: 0.307744  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.444957 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.367410  [   64/60000]\n",
      "loss: 0.397410  [ 6464/60000]\n",
      "loss: 0.451454  [12864/60000]\n",
      "loss: 0.445105  [19264/60000]\n",
      "loss: 0.261572  [25664/60000]\n",
      "loss: 0.417597  [32064/60000]\n",
      "loss: 0.506822  [38464/60000]\n",
      "loss: 0.538677  [44864/60000]\n",
      "loss: 0.419685  [51264/60000]\n",
      "loss: 0.434724  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.444805 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.355369  [   64/60000]\n",
      "loss: 0.326341  [ 6464/60000]\n",
      "loss: 0.412708  [12864/60000]\n",
      "loss: 0.488965  [19264/60000]\n",
      "loss: 0.457934  [25664/60000]\n",
      "loss: 0.582347  [32064/60000]\n",
      "loss: 0.386019  [38464/60000]\n",
      "loss: 0.368424  [44864/60000]\n",
      "loss: 0.667448  [51264/60000]\n",
      "loss: 0.299691  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.444274 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.474897  [   64/60000]\n",
      "loss: 0.407425  [ 6464/60000]\n",
      "loss: 0.407689  [12864/60000]\n",
      "loss: 0.317758  [19264/60000]\n",
      "loss: 0.375517  [25664/60000]\n",
      "loss: 0.376012  [32064/60000]\n",
      "loss: 0.398100  [38464/60000]\n",
      "loss: 0.425147  [44864/60000]\n",
      "loss: 0.475382  [51264/60000]\n",
      "loss: 0.331667  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.440683 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.400842  [   64/60000]\n",
      "loss: 0.430735  [ 6464/60000]\n",
      "loss: 0.540150  [12864/60000]\n",
      "loss: 0.489477  [19264/60000]\n",
      "loss: 0.299247  [25664/60000]\n",
      "loss: 0.305914  [32064/60000]\n",
      "loss: 0.403650  [38464/60000]\n",
      "loss: 0.294274  [44864/60000]\n",
      "loss: 0.447547  [51264/60000]\n",
      "loss: 0.292268  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.443760 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.317185  [   64/60000]\n",
      "loss: 0.710594  [ 6464/60000]\n",
      "loss: 0.221567  [12864/60000]\n",
      "loss: 0.586455  [19264/60000]\n",
      "loss: 0.425254  [25664/60000]\n",
      "loss: 0.430594  [32064/60000]\n",
      "loss: 0.479903  [38464/60000]\n",
      "loss: 0.414128  [44864/60000]\n",
      "loss: 0.278586  [51264/60000]\n",
      "loss: 0.487661  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.439511 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.446691  [   64/60000]\n",
      "loss: 0.462854  [ 6464/60000]\n",
      "loss: 0.397353  [12864/60000]\n",
      "loss: 0.685873  [19264/60000]\n",
      "loss: 0.237861  [25664/60000]\n",
      "loss: 0.330813  [32064/60000]\n",
      "loss: 0.366637  [38464/60000]\n",
      "loss: 0.416319  [44864/60000]\n",
      "loss: 0.296388  [51264/60000]\n",
      "loss: 0.396342  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.440709 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.394990  [   64/60000]\n",
      "loss: 0.419247  [ 6464/60000]\n",
      "loss: 0.247668  [12864/60000]\n",
      "loss: 0.503930  [19264/60000]\n",
      "loss: 0.395443  [25664/60000]\n",
      "loss: 0.523827  [32064/60000]\n",
      "loss: 0.330924  [38464/60000]\n",
      "loss: 0.375141  [44864/60000]\n",
      "loss: 0.291732  [51264/60000]\n",
      "loss: 0.282689  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.441059 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.458978  [   64/60000]\n",
      "loss: 0.242076  [ 6464/60000]\n",
      "loss: 0.383800  [12864/60000]\n",
      "loss: 0.238948  [19264/60000]\n",
      "loss: 0.317978  [25664/60000]\n",
      "loss: 0.451132  [32064/60000]\n",
      "loss: 0.314488  [38464/60000]\n",
      "loss: 0.541484  [44864/60000]\n",
      "loss: 0.513760  [51264/60000]\n",
      "loss: 0.447733  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.440220 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.256068  [   64/60000]\n",
      "loss: 0.532025  [ 6464/60000]\n",
      "loss: 0.588062  [12864/60000]\n",
      "loss: 0.363096  [19264/60000]\n",
      "loss: 0.526590  [25664/60000]\n",
      "loss: 0.311075  [32064/60000]\n",
      "loss: 0.429889  [38464/60000]\n",
      "loss: 0.356518  [44864/60000]\n",
      "loss: 0.423693  [51264/60000]\n",
      "loss: 0.455022  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.436759 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.275563  [   64/60000]\n",
      "loss: 0.379813  [ 6464/60000]\n",
      "loss: 0.613127  [12864/60000]\n",
      "loss: 0.517655  [19264/60000]\n",
      "loss: 0.516766  [25664/60000]\n",
      "loss: 0.527327  [32064/60000]\n",
      "loss: 0.532779  [38464/60000]\n",
      "loss: 0.392423  [44864/60000]\n",
      "loss: 0.368602  [51264/60000]\n",
      "loss: 0.473085  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.438063 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.412757  [   64/60000]\n",
      "loss: 0.301963  [ 6464/60000]\n",
      "loss: 0.520279  [12864/60000]\n",
      "loss: 0.291313  [19264/60000]\n",
      "loss: 0.440612  [25664/60000]\n",
      "loss: 0.355321  [32064/60000]\n",
      "loss: 0.484321  [38464/60000]\n",
      "loss: 0.312424  [44864/60000]\n",
      "loss: 0.421472  [51264/60000]\n",
      "loss: 0.363304  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.437151 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beforewe will have a look at whether this model can now differentiate a trouser from a t-shirt and ankle boot, we shall save the model and its parameter. Depending on the power of your computer, it is likely that the above process took quite a while and if you can avoid it you do not want to redo this work (after all, how many cups of tea can you drink!).\n",
    "\n",
    "The model and its parameters can be saved as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_{}_{}'.format(int(datetime.timestamp(datetime.now())), epochs)\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1697308300"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(datetime.timestamp(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall how, before training the model, it was unable to detect that a picture depicted an ankle boot. So let's try this again. We feed the image back into the model (`ds_train[15][0]`) and check out the probabilities for the 10 clsses. Ankle boots are the last class so we are hoping for nine numbers close to 0 followed by a number close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3886e-09, 2.4075e-11, 1.6684e-10, 1.2697e-10, 2.4469e-11, 1.5385e-03,\n",
      "         1.6970e-09, 8.7893e-03, 5.5127e-06, 9.8967e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = model(ds_train[15][0])\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "print(pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a success. The model tells us that there is a 98.97% probability that the item is indeed an ankle boot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
