{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial Workthrough\n",
    "\n",
    "Here we work through a basic example in PyTorch. It is the example used in the [PyTorch Tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html). The material heavily relies on the excellent material in that tutorial. The presentation is similar but with a slightly different emphasis. In particular this is written from the perspective of an econometrician and some parallels and differences to traditional econometric techniques will be pointed out.\n",
    "\n",
    "\n",
    "## Load some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "The PyTorch library expects data inputs as tensors. For example, here we load some inflation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inflation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960-01-01</th>\n",
       "      <td>-0.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-01-02</th>\n",
       "      <td>0.341297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-01-03</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-01-04</th>\n",
       "      <td>0.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-01-05</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>0.331073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>0.505904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>0.251844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>0.322891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>0.190752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>763 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            inflation\n",
       "DATE                 \n",
       "1960-01-01  -0.340136\n",
       "1960-01-02   0.341297\n",
       "1960-01-03   0.000000\n",
       "1960-01-04   0.340136\n",
       "1960-01-05   0.000000\n",
       "...               ...\n",
       "2023-01-03   0.331073\n",
       "2023-01-04   0.505904\n",
       "2023-01-05   0.251844\n",
       "2023-01-06   0.322891\n",
       "2023-01-07   0.190752\n",
       "\n",
       "[763 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('datasets/CPALTT01USM657N.csv')\n",
    "data.tail()\n",
    "data['DATE'] = pd.to_datetime(data['DATE'])\n",
    "data.set_index('DATE', inplace=True)\n",
    "data.rename(columns={'CPALTT01USM657N': 'inflation'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can be transformed into a tensor like so, where we use the `values()` property of the dataframe. The resulting tensor has properties `shape` and `type` which give you the relevant shape and type information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([763, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor(data.values)\n",
    "tensor.dtype\n",
    "tensor.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are basically multi-dimensional matrices and you can do arithmatic with these. Find a [list of operations](https://pytorch.org/docs/stable/torch.html) to see what is available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data\n",
    "\n",
    "To follow the example in the PyTorch tutorial we need to load the Fashion-MNIST dataset. This dataset is already in the right format and we obtain a training and a testing portion for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are image data, for instance the first image `training_data[1]` gives you information on the 28x28 pixels of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.1608, 0.7373, 0.4039, 0.2118, 0.1882, 0.1686,\n",
       "           0.3412, 0.6588, 0.5216, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.5333, 0.8588, 0.8471, 0.8941, 0.9255, 1.0000, 1.0000, 1.0000,\n",
       "           1.0000, 0.8510, 0.8431, 0.9961, 0.9059, 0.6275, 0.1765, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.6902, 0.8706,\n",
       "           0.8784, 0.8314, 0.7961, 0.7765, 0.7686, 0.7843, 0.8431, 0.8000,\n",
       "           0.7922, 0.7882, 0.7882, 0.7882, 0.8196, 0.8549, 0.8784, 0.6431,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7373, 0.8588, 0.7843,\n",
       "           0.7765, 0.7922, 0.7765, 0.7804, 0.7804, 0.7882, 0.7686, 0.7765,\n",
       "           0.7765, 0.7843, 0.7843, 0.7843, 0.7843, 0.7882, 0.7843, 0.8824,\n",
       "           0.1608, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.8588, 0.7804, 0.7961,\n",
       "           0.7961, 0.8314, 0.9333, 0.9725, 0.9804, 0.9608, 0.9765, 0.9647,\n",
       "           0.9686, 0.9882, 0.9725, 0.9216, 0.8118, 0.7961, 0.7961, 0.8706,\n",
       "           0.5490, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.4549, 0.8863, 0.8078, 0.8000,\n",
       "           0.8118, 0.8000, 0.3961, 0.2941, 0.1843, 0.2863, 0.1882, 0.1961,\n",
       "           0.1765, 0.2000, 0.2471, 0.4431, 0.8706, 0.7922, 0.8078, 0.8627,\n",
       "           0.8784, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.7843, 0.8706, 0.8196, 0.7961,\n",
       "           0.8431, 0.7843, 0.0000, 0.2745, 0.3843, 0.0000, 0.4039, 0.2314,\n",
       "           0.2667, 0.2784, 0.1922, 0.0000, 0.8588, 0.8078, 0.8392, 0.8235,\n",
       "           0.9804, 0.1490, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9686, 0.8549, 0.8314, 0.8235,\n",
       "           0.8431, 0.8392, 0.0000, 0.9961, 0.9529, 0.5451, 1.0000, 0.6824,\n",
       "           0.9843, 1.0000, 0.8039, 0.0000, 0.8431, 0.8510, 0.8392, 0.8157,\n",
       "           0.8627, 0.3725, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.1765, 0.8863, 0.8392, 0.8392, 0.8431,\n",
       "           0.8784, 0.8039, 0.0000, 0.1647, 0.1373, 0.2353, 0.0627, 0.0667,\n",
       "           0.0471, 0.0510, 0.2745, 0.0000, 0.7412, 0.8471, 0.8314, 0.8078,\n",
       "           0.8314, 0.6118, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.6431, 0.9216, 0.8392, 0.8275, 0.8627,\n",
       "           0.8471, 0.7882, 0.2039, 0.2784, 0.3490, 0.3686, 0.3255, 0.3059,\n",
       "           0.2745, 0.2980, 0.3608, 0.3412, 0.8078, 0.8118, 0.8706, 0.8353,\n",
       "           0.8588, 0.8157, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.4157, 0.7333, 0.8745, 0.9294, 0.9725,\n",
       "           0.8275, 0.7765, 0.9882, 0.9804, 0.9725, 0.9608, 0.9725, 0.9882,\n",
       "           0.9922, 0.9804, 0.9882, 0.9373, 0.7882, 0.8314, 0.8824, 0.8431,\n",
       "           0.7569, 0.4431, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.2118, 0.6235,\n",
       "           0.8706, 0.7569, 0.8157, 0.7529, 0.7725, 0.7843, 0.7843, 0.7843,\n",
       "           0.7843, 0.7882, 0.7961, 0.7647, 0.8235, 0.6471, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843,\n",
       "           0.8824, 0.7529, 0.8392, 0.7961, 0.8078, 0.8000, 0.8000, 0.8039,\n",
       "           0.8078, 0.8000, 0.8314, 0.7725, 0.8549, 0.4196, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0235, 0.0000, 0.1804,\n",
       "           0.8314, 0.7647, 0.8314, 0.7922, 0.8078, 0.8039, 0.8000, 0.8039,\n",
       "           0.8078, 0.8000, 0.8314, 0.7843, 0.8549, 0.3569, 0.0000, 0.0118,\n",
       "           0.0039, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0431,\n",
       "           0.7725, 0.7804, 0.8039, 0.7922, 0.8039, 0.8078, 0.8000, 0.8039,\n",
       "           0.8118, 0.8000, 0.8039, 0.8039, 0.8549, 0.3020, 0.0000, 0.0196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.0078,\n",
       "           0.7490, 0.7765, 0.7882, 0.8039, 0.8078, 0.8039, 0.8039, 0.8078,\n",
       "           0.8196, 0.8078, 0.7804, 0.8196, 0.8588, 0.2902, 0.0000, 0.0196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000,\n",
       "           0.7373, 0.7725, 0.7843, 0.8118, 0.8118, 0.8000, 0.8118, 0.8118,\n",
       "           0.8235, 0.8157, 0.7765, 0.8118, 0.8667, 0.2824, 0.0000, 0.0157,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000,\n",
       "           0.8431, 0.7765, 0.7961, 0.8078, 0.8157, 0.8039, 0.8118, 0.8118,\n",
       "           0.8235, 0.8157, 0.7843, 0.7922, 0.8706, 0.2941, 0.0000, 0.0157,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.8314, 0.7765, 0.8196, 0.8078, 0.8196, 0.8078, 0.8157, 0.8118,\n",
       "           0.8275, 0.8078, 0.8039, 0.7765, 0.8667, 0.3137, 0.0000, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.8000, 0.7882, 0.8039, 0.8157, 0.8118, 0.8039, 0.8275, 0.8039,\n",
       "           0.8235, 0.8235, 0.8196, 0.7647, 0.8667, 0.3765, 0.0000, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.7922, 0.7882, 0.8039, 0.8196, 0.8118, 0.8039, 0.8353, 0.8078,\n",
       "           0.8235, 0.8196, 0.8235, 0.7608, 0.8510, 0.4118, 0.0000, 0.0078,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.8000, 0.8000, 0.8039, 0.8157, 0.8118, 0.8039, 0.8431, 0.8118,\n",
       "           0.8235, 0.8157, 0.8275, 0.7569, 0.8353, 0.4510, 0.0000, 0.0078,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.8000, 0.8118, 0.8118, 0.8157, 0.8078, 0.8078, 0.8431, 0.8235,\n",
       "           0.8235, 0.8118, 0.8314, 0.7647, 0.8235, 0.4627, 0.0000, 0.0078,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.7765, 0.8157, 0.8157, 0.8157, 0.8000, 0.8118, 0.8314, 0.8314,\n",
       "           0.8235, 0.8118, 0.8275, 0.7686, 0.8118, 0.4745, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.7765, 0.8235, 0.8118, 0.8157, 0.8078, 0.8196, 0.8353, 0.8314,\n",
       "           0.8275, 0.8118, 0.8235, 0.7725, 0.8118, 0.4863, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.6745, 0.8235, 0.7961, 0.7882, 0.7804, 0.8000, 0.8118, 0.8039,\n",
       "           0.8000, 0.7882, 0.8039, 0.7725, 0.8078, 0.4980, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.7373, 0.8667, 0.8392, 0.9176, 0.9255, 0.9333, 0.9569, 0.9569,\n",
       "           0.9569, 0.9412, 0.9529, 0.8392, 0.8784, 0.6353, 0.0000, 0.0078,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.5451, 0.5725, 0.5098, 0.5294, 0.5294, 0.5373, 0.4902, 0.4863,\n",
       "           0.4902, 0.4745, 0.4667, 0.4471, 0.5098, 0.2980, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the data avaialable in `test_data` and `training_data`. For certain operations it will turn out to be useful to access the data via the DataLoader. This will enable access samples of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indicated above that, if iterating through the data, we get random items. Each item has an image and a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfOklEQVR4nO3df2xV9f3H8delPy4F2zsbbO/tgFodymIJicD4EX8AzoZmwyFbgpossC1GJ5CR6sgYS2yWjBoSicmYbHMLk0wm/6gjwsQ6aNEwDBIchKnBWKRGrh0IvW2BW9ue7x98vbPy8/Px3vvuvX0+kpvQe8+b8+7nHnj19N7zvqEgCAIBAGBghHUDAIDhixACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAmULrBr5sYGBAH3/8sUpLSxUKhazbAQA4CoJAXV1dqqqq0ogRlz/XGXIh9PHHH2vcuHHWbQAAvqL29naNHTv2stsMuRAqLS21bgEZdKWfii6msND9MPWdRtXX15e1fcGPz29IeI5sXM3/5xl7Tejpp59WTU2NRo4cqSlTpuj111+/qjp+BZffQqEQN88bzmPtcsfVrH1GQmjLli1asWKFVq9erQMHDuj2229XfX29jh07londAQByVCgTU7SnT5+uW2+9VRs2bEjd981vflMLFixQU1PTZWsTiYQikUi6W8IQUVBQ4FzDr+Oyu5+hzudXugMDAxnoBFfS2dmpsrKyy26T9jOh3t5e7d+/X3V1dYPur6ur0549ey7YPplMKpFIDLoBAIaHtIfQiRMn1N/fr8rKykH3V1ZWKh6PX7B9U1OTIpFI6sY74wBg+MjYGxO+/IJUEAQXfZFq1apV6uzsTN3a29sz1RIAYIhJ+1u0x4wZo4KCggvOejo6Oi44O5KkcDiscDic7jYAADkg7WdCxcXFmjJlipqbmwfd39zcrFmzZqV7dwCAHJaRi1UbGhr0wx/+UFOnTtXMmTP1xz/+UceOHdPDDz+cid0BAHJURkJo0aJFOnnypH7961/r+PHjqq2t1fbt21VdXZ2J3QEAclRGrhP6KrhOKHf4XPPT39+fgU5wKXPmzPGq+9nPfuZc8/LLLzvX/OlPf3Ku8eFzrZnkd90Y/sfkOiEAAK4WIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAMwwwhdcgUil7w0i3bNniXPPiiy967ev55593rrn22muda77zne841/zhD39wrvF9jpLJpHNNUVGRc82BAweca3yHsvoYMcL953Sf/1KH2H/DacMAUwDAkEYIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMMMU7TzjM/V3YGAgA51c3O7du51rbr/99gx0cnHLli1zrjl8+LBzza5du5xrTp8+7Vzz7rvvOtdI0qhRo5xriouLnWsqKyuda3zW4YYbbnCu8TXU/w1mE1O0AQBDGiEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOF1g0gvQoL3Z/S3t5er32tXbvWucZnGGl3d7dzTTgcdq6RpEWLFjnXfOMb33Cu+eSTT5xrTp065VzjOww4Go061/T09DjXfPTRR841EyZMcK757W9/61wjScuXL3euyea/wXzAmRAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzoSAIAusmviiRSHgPXcw3oVDIuSabT+fBgweda8aPH+9c4zPcsb+/37lGkkaNGuVV58pn2Gc8Hneuqa6udq6RpM8++8y5xud56uvrc64ZMcL9Z+cTJ04410jS1KlTnWuG+r/bbOrs7FRZWdllt+FMCABghhACAJhJewg1NjYqFAoNuvl8NgkAIP9l5EPtbrnlFr322muprwsKCjKxGwBAjstICBUWFnL2AwC4ooy8JnTkyBFVVVWppqZG9913nz744INLbptMJpVIJAbdAADDQ9pDaPr06dq0aZN27NihZ555RvF4XLNmzdLJkycvun1TU5MikUjqNm7cuHS3BAAYojJ+nVBPT49uvPFGrVy5Ug0NDRc8nkwmlUwmU18nEgmC6P8N9esNuE7IH9cJncd1QucN5+uEMvKa0BeNHj1akyZN0pEjRy76eDgcVjgcznQbAIAhKOPXCSWTSb3zzjuKxWKZ3hUAIMekPYQee+wxtba2qq2tTW+++aZ+8IMfKJFIaPHixeneFQAgx6X913EfffSR7r//fp04cULXXXedZsyYob1793r/bhoAkL/SHkLPP/98uv/KYau4uNi55otv8rhadXV1zjWSNHHiROcanxfXBwYGnGt8+bxQXlRU5Fzj89z6/Er7v//9r3ON5Nff6NGjnWt8LmQ/ffq0c01lZaVzjSSv6x19jvHCQvf/in2O1aGI2XEAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMZPxD7eDPZxipD9+hsz79+Qys9PmkSp8BnL778vkUUp/+fGq+9rWvOddI2Vtzn8GdPnw/MfcnP/mJc81vfvMb5xrfTwLOB5wJAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMhIIgCKyb+KJEIqFIJGLdRtr5TBju7e11rqmrq3Ou+cc//uFcI0mffPKJc83IkSOda3wOUd/D2qfOZ+K0zzRxn0nLvtPEffisnc8E8jNnzjjX+E6p7u7udq6ZNGmS177yUWdnp8rKyi67DWdCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBRaNzBcjBiRnbyfN2+ec41vb4WF2Tl8fIae+g6s9Bmo6bOvbA1l9RmCK0lFRUVeda58hr+Gw2Hnmk8//dS5RsruANjhijMhAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZhhgmiU+gzF9dHV1ZWU/kt8gyZKSEueavr4+5xrf4ao+AzV9Bov67MdHQUGBV53PAFOfNT937pxzTXd3t3ON7/EwevRo55p77rnHuWbr1q3ONfmCMyEAgBlCCABgxjmEdu/erfnz56uqqkqhUEgvvfTSoMeDIFBjY6OqqqpUUlKi2bNn6/Dhw+nqFwCQR5xDqKenR5MnT9b69esv+vjatWu1bt06rV+/Xvv27VM0GtXdd9+d1dcqAAC5wfnVuvr6etXX11/0sSAI9NRTT2n16tVauHChJOnZZ59VZWWlNm/erIceeuirdQsAyCtpfU2ora1N8XhcdXV1qfvC4bDuvPNO7dmz56I1yWRSiURi0A0AMDykNYTi8bgkqbKyctD9lZWVqce+rKmpSZFIJHUbN25cOlsCAAxhGXl33JevgQiC4JLXRaxatUqdnZ2pW3t7eyZaAgAMQWm9WDUajUo6f0YUi8VS93d0dFxwdvS5cDjsddEjACD3pfVMqKamRtFoVM3Nzan7ent71draqlmzZqVzVwCAPOB8JtTd3a33338/9XVbW5vefvttlZeXa/z48VqxYoXWrFmjCRMmaMKECVqzZo1GjRqlBx54IK2NAwByn3MIvfXWW5ozZ07q64aGBknS4sWL9Ze//EUrV67U2bNn9cgjj+jUqVOaPn26Xn31VZWWlqavawBAXggFPtMXMyiRSCgSiVi3kXbZGoxZUVHhXPPhhx8610jnL1x25bMOPkM4fQd3FhcXZ2Vf/f39zjUjRrj/9txnQKgkXXPNNc41GzdudK7x+TX9F19vvlqnT592rpH81vytt95yrrn33nuda3JBZ2enysrKLrsNs+MAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGbS+smquLRsDStfuXKlc43vxOm+vj7nmqKioqzsx6dGkpLJpHONz6Rln08THhgYcK7xmYbt68c//rFzzT//+U/nmptvvtm5JpFIONdI5z+U05VPf8MZZ0IAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMMMA0zzz66KPONb7DHUOhkHONz7DPbA1/lfyGhPqsg0+N71BWH2+88UZW9vPvf//buWbu3LkZ6OTifAaY3nDDDRnoJH9xJgQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMBMKMjmdMirkEgkFIlErNsYEq6//nrnmkOHDjnXnDlzxrlGkgoL3eff+gzu9OG7H58Bpj7rUFRU5FzT39+flf1IUjgcdq7xWXOfY7ytrc25Jh6PO9dI0okTJ5xramtrnWt81ttnuGq2dXZ2qqys7LLbcCYEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADAjPvkRWTNihUrnGt8BiGeO3fOuUYa2sNIs9WbJI0Y4f6zXF9fn3NNQUGBc43vcFqf48jH0aNHs7Kfa665xqsukUikuZOLu/XWW51r9u7dm4FOso8zIQCAGUIIAGDGOYR2796t+fPnq6qqSqFQSC+99NKgx5csWaJQKDToNmPGjHT1CwDII84h1NPTo8mTJ2v9+vWX3GbevHk6fvx46rZ9+/av1CQAID85vzGhvr5e9fX1l90mHA4rGo16NwUAGB4y8ppQS0uLKioqdNNNN+nBBx9UR0fHJbdNJpNKJBKDbgCA4SHtIVRfX6/nnntOO3fu1JNPPql9+/Zp7ty5SiaTF92+qalJkUgkdRs3bly6WwIADFFpv05o0aJFqT/X1tZq6tSpqq6u1rZt27Rw4cILtl+1apUaGhpSXycSCYIIAIaJjF+sGovFVF1drSNHjlz08XA4nLUL4wAAQ0vGrxM6efKk2tvbFYvFMr0rAECOcT4T6u7u1vvvv5/6uq2tTW+//bbKy8tVXl6uxsZGff/731csFtPRo0f1y1/+UmPGjNG9996b1sYBALnPOYTeeustzZkzJ/X156/nLF68WBs2bNChQ4e0adMmnT59WrFYTHPmzNGWLVtUWlqavq4BAHnBOYRmz56tIAgu+fiOHTu+UkP4nx/96EfONZ999plzjc9gTCm7Q0JdXe4YvRyfYaQ+BgYGnGt8nief/fj69re/7Vzz2muvOdf4DO6cMmWKc42UvWN84sSJzjUMMAUA4CsihAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJjJ+Cerwl9ZWZlzTWdnp3ON76TgoTxF23d6tM/3NJQnb/v2lkwmnWuuv/56r3258pm8PW3aNK99+U6Yd1VZWZmV/QxFnAkBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwwwDTLIlEIlnZj8+Qy8JCv8MgCAKvumzsJ1tDRSW/oac+31O21luSiouLnWvGjx+fgU4utG3bNuean//85177ytZx5PtvMB9wJgQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMDM8J2al2U333yzdQuX5DP0VPIb3Jmtmv7+fucaSSooKMjKvnp7e51rfIaK+qyd5Dcs9cyZM177cnX69GnnGt/hrz7Hg89zG41GnWvyBWdCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzDDANEumTJniXOMzdNGnZsQIv59FfAefusrm91RY6P5P4rPPPnOuKSoqcq7x6a2vr8+5RvIbfHru3DmvfbnyOR6yOaTXZx2uv/5655p8wZkQAMAMIQQAMOMUQk1NTZo2bZpKS0tVUVGhBQsW6L333hu0TRAEamxsVFVVlUpKSjR79mwdPnw4rU0DAPKDUwi1trZq6dKl2rt3r5qbm9XX16e6ujr19PSktlm7dq3WrVun9evXa9++fYpGo7r77rvV1dWV9uYBALnN6ZXOV155ZdDXGzduVEVFhfbv36877rhDQRDoqaee0urVq7Vw4UJJ0rPPPqvKykpt3rxZDz30UPo6BwDkvK/0mlBnZ6ckqby8XJLU1tameDyuurq61DbhcFh33nmn9uzZc9G/I5lMKpFIDLoBAIYH7xAKgkANDQ267bbbVFtbK0mKx+OSpMrKykHbVlZWph77sqamJkUikdRt3Lhxvi0BAHKMdwgtW7ZMBw8e1N/+9rcLHvvye+uDILjk++1XrVqlzs7O1K29vd23JQBAjvG6WHX58uXaunWrdu/erbFjx6buj0ajks6fEcVisdT9HR0dF5wdfS4cDiscDvu0AQDIcU5nQkEQaNmyZXrhhRe0c+dO1dTUDHq8pqZG0WhUzc3Nqft6e3vV2tqqWbNmpadjAEDecDoTWrp0qTZv3qy///3vKi0tTb3OE4lEVFJSolAopBUrVmjNmjWaMGGCJkyYoDVr1mjUqFF64IEHMvINAAByl1MIbdiwQZI0e/bsQfdv3LhRS5YskSStXLlSZ8+e1SOPPKJTp05p+vTpevXVV1VaWpqWhgEA+cMphK5mcGAoFFJjY6MaGxt9e8pL9fX1zjU+wyd9hjv6DOD03ZfPYFGf4ZMFBQXONZLf9+QzsLK3t9e5ZuTIkc41vs9tf3+/c43PsE8fx48fd67xHa7qM2j2ixfvXy3fgbv5YPh+5wAAc4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM16frAp3O3fudK656667nGuyOY23uLjYucZnqrPPRGefGslvYrfPRGyf/nzWzqc3yW+auM/a+UgkEs415eXlXvv69NNPnWt81tx32nk+4EwIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGQaYZslTTz3lXPOrX/3Kuaavr8+5pr293blG8htyec011zjXjB492rnGZx186woKCpxrfIa/+gzG9NmPJIVCIeeaUaNGee0rG5LJpFedzzr4DBH2fZ7yAWdCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzDDAdAgrKipyrvnkk0+ca3yGNEp+Qxc7OjqcayKRiHPNwMCAc40kXXvttc41Ps/TqVOnnGu6u7uda0pKSpxrJL819xncmS3xeNyrLlvr4DOkN18M3aMGAJD3CCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmGGA6RDmMzzRx8SJE73qfAaY+gx3DILAucZnqKgkjRw50rnGZ7Dou+++61xz7tw55xpfPoNPz549m4FO0uPIkSNedTNmzHCu6e3tda7xOe7yBWdCAAAzhBAAwIxTCDU1NWnatGkqLS1VRUWFFixYoPfee2/QNkuWLFEoFBp08zmlBQDkP6cQam1t1dKlS7V37141Nzerr69PdXV16unpGbTdvHnzdPz48dRt+/btaW0aAJAfnN6Y8Morrwz6euPGjaqoqND+/ft1xx13pO4Ph8OKRqPp6RAAkLe+0mtCnZ2dkqTy8vJB97e0tKiiokI33XSTHnzwwct+pHMymVQikRh0AwAMD94hFASBGhoadNttt6m2tjZ1f319vZ577jnt3LlTTz75pPbt26e5c+cqmUxe9O9pampSJBJJ3caNG+fbEgAgx3hfJ7Rs2TIdPHhQb7zxxqD7Fy1alPpzbW2tpk6dqurqam3btk0LFy684O9ZtWqVGhoaUl8nEgmCCACGCa8QWr58ubZu3ardu3dr7Nixl902Foupurr6kheLhcNhhcNhnzYAADnOKYSCINDy5cv14osvqqWlRTU1NVesOXnypNrb2xWLxbybBADkJ6fXhJYuXaq//vWv2rx5s0pLSxWPxxWPx1PjOrq7u/XYY4/pX//6l44ePaqWlhbNnz9fY8aM0b333puRbwAAkLuczoQ2bNggSZo9e/ag+zdu3KglS5aooKBAhw4d0qZNm3T69GnFYjHNmTNHW7ZsUWlpadqaBgDkB+dfx11OSUmJduzY8ZUaAgAMH0zRhtdEZ+S3bE3E9pmqPjAw4Fzz8ssvO9dI0l133eVc4zP1vbBw+P5XzABTAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZkKBz7S9DEokEopEItZtDAmhUMi5xmcgpE+N5NdftmSzN59/Qv39/VnZjy+f9fP5nnz247MOo0aNcq6RpDfffNO5pry83Lnmnnvuca7Zv3+/c022dXZ2qqys7LLbcCYEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOF1g182RAbZWfKZy2yVYP/4Xnyl63vyXc/3d3dzjVFRUXONT5z93LB1az7kAuhrq4u6xZy2sDAQFZqkN/yLfDOnj3rVTdz5sw0dzK8dHV1XXEg9ZCboj0wMKCPP/5YpaWlF0zYTSQSGjdunNrb2684mTWfsQ7nsQ7nsQ7nsQ7nDYV1CIJAXV1dqqqquuKU/iF3JjRixAiNHTv2stuUlZUN64Psc6zDeazDeazDeazDedbrcLUfycMbEwAAZgghAICZnAqhcDisxx9/XOFw2LoVU6zDeazDeazDeazDebm2DkPujQkAgOEjp86EAAD5hRACAJghhAAAZgghAICZnAqhp59+WjU1NRo5cqSmTJmi119/3bqlrGpsbFQoFBp0i0aj1m1l3O7duzV//nxVVVUpFArppZdeGvR4EARqbGxUVVWVSkpKNHv2bB0+fNim2Qy60josWbLkguNjxowZNs1mSFNTk6ZNm6bS0lJVVFRowYIFeu+99wZtMxyOh6tZh1w5HnImhLZs2aIVK1Zo9erVOnDggG6//XbV19fr2LFj1q1l1S233KLjx4+nbocOHbJuKeN6eno0efJkrV+//qKPr127VuvWrdP69eu1b98+RaNR3X333Xk3h/BK6yBJ8+bNG3R8bN++PYsdZl5ra6uWLl2qvXv3qrm5WX19faqrq1NPT09qm+FwPFzNOkg5cjwEOeJb3/pW8PDDDw+6b+LEicEvfvELo46y7/HHHw8mT55s3YYpScGLL76Y+npgYCCIRqPBE088kbrv3LlzQSQSCX7/+98bdJgdX16HIAiCxYsXB9/73vdM+rHS0dERSApaW1uDIBi+x8OX1yEIcud4yIkzod7eXu3fv191dXWD7q+rq9OePXuMurJx5MgRVVVVqaamRvfdd58++OAD65ZMtbW1KR6PDzo2wuGw7rzzzmF3bEhSS0uLKioqdNNNN+nBBx9UR0eHdUsZ1dnZKUkqLy+XNHyPhy+vw+dy4XjIiRA6ceKE+vv7VVlZOej+yspKxeNxo66yb/r06dq0aZN27NihZ555RvF4XLNmzdLJkyetWzPz+fM/3I8NSaqvr9dzzz2nnTt36sknn9S+ffs0d+5cJZNJ69YyIggCNTQ06LbbblNtba2k4Xk8XGwdpNw5HobcFO3L+fJHOwRBcMF9+ay+vj7150mTJmnmzJm68cYb9eyzz6qhocGwM3vD/diQpEWLFqX+XFtbq6lTp6q6ulrbtm3TwoULDTvLjGXLlungwYN64403LnhsOB0Pl1qHXDkecuJMaMyYMSooKLjgJ5mOjo4LfuIZTkaPHq1JkybpyJEj1q2Y+fzdgRwbF4rFYqqurs7L42P58uXaunWrdu3aNeijX4bb8XCpdbiYoXo85EQIFRcXa8qUKWpubh50f3Nzs2bNmmXUlb1kMql33nlHsVjMuhUzNTU1ikajg46N3t5etba2DutjQ5JOnjyp9vb2vDo+giDQsmXL9MILL2jnzp2qqakZ9PhwOR6utA4XM2SPB8M3RTh5/vnng6KiouDPf/5z8J///CdYsWJFMHr06ODo0aPWrWXNo48+GrS0tAQffPBBsHfv3uC73/1uUFpamvdr0NXVFRw4cCA4cOBAIClYt25dcODAgeDDDz8MgiAInnjiiSASiQQvvPBCcOjQoeD+++8PYrFYkEgkjDtPr8utQ1dXV/Doo48Ge/bsCdra2oJdu3YFM2fODL7+9a/n1Tr89Kc/DSKRSNDS0hIcP348dTtz5kxqm+FwPFxpHXLpeMiZEAqCIPjd734XVFdXB8XFxcGtt9466O2Iw8GiRYuCWCwWFBUVBVVVVcHChQuDw4cPW7eVcbt27QokXXBbvHhxEATn35b7+OOPB9FoNAiHw8Edd9wRHDp0yLbpDLjcOpw5cyaoq6sLrrvuuqCoqCgYP358sHjx4uDYsWPWbafVxb5/ScHGjRtT2wyH4+FK65BLxwMf5QAAMJMTrwkBAPITIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM/8HHWMQ3yyH4XgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = training_data[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations\n",
    "\n",
    "Neural Network models need data input in very controlled scales. Examples are standardised variables (mean 0 and variance 1) or data mapped into a $[0,1]$ interval. In fact, when we imported the Fashion data earlier, we called `transform=ToTensor()`. This ensured that the pixel information was mapped into the $[0,1]$ intervall. The `target` variable, which is the label, however, came as an integer in $[0,9]$. By reloading the data with the `target_transform` as below, we change the label into 10 indicator variables with all but one taking the value 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")\n",
    "\n",
    "ds_test = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us extract the 15th item out of `ds_train`, show it and see what type of item it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "img, label = ds_train[14]\n",
    "img = img.squeeze()\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the third last indicator variable is 1. That corresponds to label 7, a sneaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "\n",
    "Now that the data are prepared we need to build the model. This is done using the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will return to the details of the above setup a little later. For now just accept it.\n",
    "\n",
    "But what is useful to understand what the above code did. It defined a `class` called `NeuralNetwork`. This will allow us to soon define a particular object (in computing speak an \"instance\" of that type of object) of that class. More on this later. \n",
    "\n",
    "Estimating, or training in the language of machine learning, a neural network model can by computing intensive. So we want to use the best possible hardware to do so. The following bit of code checks whether you have any special resources available. If not, then your computer's CPU will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shall define one instance of the `NeuralNetwork` type of objects, and we call it `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the model eventually maps the 784 (28x28 pixels) into 10 output items (the 10 different labels). In other words, we feed in an image (as defined by 728 pixels) and we receive information in terms of 10 outputs (the 10 possible labels).\n",
    "\n",
    "Let us now define a random image and then we print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "plt.imshow(X.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is just noise. We shouldn't expect to see any particular item of clothing in here. But anyways, let's see whether our Neural Network can detect anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1036, 0.0926, 0.1085, 0.0980, 0.1054, 0.1057, 0.0985, 0.0863, 0.0991,\n",
      "         0.1022]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "print(pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you see here are the predicted probabilities for each of the 10 item classes (from t-shirt to ankle boots). You can see that these probabilities are all between 8 and 11% and in fact they sum to 1. This is not surprising as the random image does not look anythink like any of the items in our list. The max prob here is the probability of 10.55% for a bag.\n",
    "\n",
    "Let's see how the model does with one of our images from the test dataset (`ds_test`). We will pick the 15th image from the training dataset. We'll first print the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "img, label = ds_train[15]\n",
    "img = img.squeeze()\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an image of an ankle boot. Now we feed this into our network. Will it identify the picture as an ankle boot? `ds_test[15]` picks the 15th item but there are two elements, the image as the first element (`[0]`) and the label as the second element (`[1]`). So `ds_test[15][0]` picks the image only as we feed it into `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0998, 0.0984, 0.1002, 0.0960, 0.1046, 0.0995, 0.1004, 0.1011, 0.1008,\n",
      "         0.0992]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logits = model(ds_test[15][0])\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "print(pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is basically as for the random image. All labels have a probability around 10%. Why is that. Well, so far we only initiated a network architecture (which includes some random model coefficients). The network has not seen any data yet which it could use to optimise the parameters such that it recognises an ankle boot.\n",
    "\n",
    "In fact you can see what the parameters for the model are (as we initialised it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0297,  0.0263,  0.0138,  ..., -0.0131,  0.0120, -0.0164],\n",
      "        [ 0.0346, -0.0287,  0.0091,  ..., -0.0123,  0.0311, -0.0298]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0228, -0.0062], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0220,  0.0044,  0.0110,  ..., -0.0281,  0.0192,  0.0105],\n",
      "        [ 0.0386,  0.0081,  0.0199,  ..., -0.0146,  0.0272,  0.0065]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0435, 0.0289], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0065, -0.0235, -0.0108,  ...,  0.0063,  0.0213,  0.0227],\n",
      "        [ 0.0048,  0.0346, -0.0352,  ..., -0.0381, -0.0037, -0.0251]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0425, -0.0273], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact there are an awful lot of parameters: $(784*512)+ 512+(512*512)+512+(512*10)+10 =669,706$. Almost $700,000$ parameters. The number is a result of the model architecture we defined as we defined the `NeuralNetwork` class. Let us look at a graphical representation of what we build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with an image that is represented by 784 pieces of information, say $X_i$ for $i = 1,..., 784. (#0)\n",
    "\n",
    "Each of the units in the first hidden layer (#1) represents a linear combination of these 784 pieces of information into a unit in the first hidden layer, think, $Lin^{(1)}_k=\\sum^{784}_{i=1}\\omega^{(1)}_{ki}X_i$ for the $k$ th of these units. That means that into each of these units we have 784 values and a parameter for each, and then you find 512 units. \n",
    "\n",
    "Each of these units you can think of as a function which combines the linear combination of all the image information ($Lin^{(1)}_k$) into an output $Lout^{(1)}_k=g(\\omega^{(1)}_{k0}+Lin^{(1)}_k)$. This requires another parameter for each unit $k$, $\\omega^{(1)}_{k0}$ and a function $g()$. In the setup we set this function to be a rectified linear activation function (`nn.ReLU()`). This is an extremely simple function of the form $g(x)=max(0,x)$.\n",
    "\n",
    "The 2nd hidden layer (#2) functions very much in the same manner. All inputs (= all outputs from the previous layer) are linearily combined into the input for the $k$th unit in the second layer, $Lin^{(2)}_k=\\sum^{512}_{i=1}\\omega^{(2)}_{ki}Lout^{(1)}_i$. This implies that there are $512*512$ parameters ($\\omega^{(2)}_{ki}$) at this stage. Again, as we specified in our class definition, the function that combines these into an output for unit $k$ is `nn.ReLU()`, $Lout^{(2)}_k=g(\\omega^{(2)}_{k0}+Lin^{(2)}_k)$. This requires 512 additional parameters, $\\omega^{(2)}_{k0}$.\n",
    "\n",
    "Finally, layer #3 defines the model outputs. Here we have 10, as specified in the class setup (`nn.Linear(512, 10)`). Each of these is a linear combination of the 512 outputs from layer 2, $Y_k=\\sum^{512}_{i=1}\\omega^{(o)}_{ki}Lout^{(2)}_i$. As we have 10 such outputs, this delivers $10*512$ additional parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NeuralNetwork Structure](images/NNstructure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have almost $700,000$ parameters and initially they are all chosen to take some random values. We shouldn't be surprised that the model was unable to distinguish an ankle boot from a t-shirt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate/Optimise/Train the model\n",
    "\n",
    "We now turn attention to the model optimisation. An econometrician would call this parameter estimation, in data science this is typically called the training o fthe model.\n",
    "\n",
    "Recall that earlier, we initiated an instance of our neural network, `model`, by calling the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any code after that line was just for illustration purposes of the networks working. So let's go back to the stage where we just initiated `model`. As discussed before the model will have been initiated with some random parameters.\n",
    "\n",
    "In order to find the best parameters that allow the model to differentiate an ankle boot from a t-shirt we will need to feed the network some data, we call this this the training data set, `ds_train`, for which we know what categories of items they are. The parameters are adjusted to keep improving the model's categorisation of these data. This is a nonlinear optimisation process, in other words it is an iterative process which potentially never ends. \n",
    "\n",
    "To make this a feasible process we have to give Python (or better `torch`) a few instructions for this process. These instructions come in the form of what is commonly called hyperparameters. Typical hyperparameters are\n",
    "\n",
    "* Number of epochs, or number of parameter improvement iterations \n",
    "* Batch size, this tells torch how many pictures to feed into the model in order to find the next improvement\n",
    "* Learning rate, this instructs torch how quickly to update parameters\n",
    "\n",
    "We adopt the same values chosen in the Torch tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing these differently will give you slightly different results. However, in the end, the idea is that these should be chosen such that the results are not sensitive to sensible changes in tehse parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some further choices to be made, namely the loss function and the algorithm.\n",
    "\n",
    "### Loss function\n",
    "\n",
    "As econometricians we are familiar with loss functions like the residual sum of squares (which we aim to minimise) or the (log-)likelihood function (which we aim to maximise). Both of these are available to users. Here however we use a different loss function called the `nn.CrossEntropyLoss`. In effect we are comparing distributions. The real outcome, say of our test ankle boot is a 1x10 vector of values with all but the last element being a 0, the last being equal to 1. Think of this as a discrete distribution.\n",
    "\n",
    "As you have seen, the output of the neural network we build is also a 1x10 vector of probabilities. Ideally we wish that the network predicts the right label (high probability on ankle boot and close to 0 probability for the other labels). Therefore, the closer the output vector is to the input label vector, the better our model does. \n",
    "\n",
    "The `nn.CrossEntropyLoss` loss function can be used to compare such vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation algorithm\n",
    "\n",
    "The process of updating the parameters (`model.parameters()`) to improve the model is an iterative one. The learning rate is one of the hyperparameters listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305326  [   64/60000]\n",
      "loss: 2.289036  [ 6464/60000]\n",
      "loss: 2.276953  [12864/60000]\n",
      "loss: 2.262890  [19264/60000]\n",
      "loss: 2.240948  [25664/60000]\n",
      "loss: 2.242036  [32064/60000]\n",
      "loss: 2.212817  [38464/60000]\n",
      "loss: 2.213861  [44864/60000]\n",
      "loss: 2.186198  [51264/60000]\n",
      "loss: 2.193768  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 2.170360 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.185197  [   64/60000]\n",
      "loss: 2.175004  [ 6464/60000]\n",
      "loss: 2.135464  [12864/60000]\n",
      "loss: 2.087795  [19264/60000]\n",
      "loss: 2.104789  [25664/60000]\n",
      "loss: 2.035072  [32064/60000]\n",
      "loss: 2.047997  [38464/60000]\n",
      "loss: 2.015226  [44864/60000]\n",
      "loss: 1.998038  [51264/60000]\n",
      "loss: 1.913921  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 1.931528 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.916316  [   64/60000]\n",
      "loss: 1.928624  [ 6464/60000]\n",
      "loss: 1.850737  [12864/60000]\n",
      "loss: 1.855171  [19264/60000]\n",
      "loss: 1.834798  [25664/60000]\n",
      "loss: 1.744976  [32064/60000]\n",
      "loss: 1.686930  [38464/60000]\n",
      "loss: 1.641059  [44864/60000]\n",
      "loss: 1.656805  [51264/60000]\n",
      "loss: 1.564776  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.571803 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.534739  [   64/60000]\n",
      "loss: 1.531053  [ 6464/60000]\n",
      "loss: 1.525390  [12864/60000]\n",
      "loss: 1.468488  [19264/60000]\n",
      "loss: 1.406947  [25664/60000]\n",
      "loss: 1.349014  [32064/60000]\n",
      "loss: 1.438531  [38464/60000]\n",
      "loss: 1.307468  [44864/60000]\n",
      "loss: 1.394831  [51264/60000]\n",
      "loss: 1.175969  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 1.282434 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.188197  [   64/60000]\n",
      "loss: 1.318095  [ 6464/60000]\n",
      "loss: 1.235144  [12864/60000]\n",
      "loss: 1.229596  [19264/60000]\n",
      "loss: 1.234889  [25664/60000]\n",
      "loss: 1.174535  [32064/60000]\n",
      "loss: 1.084742  [38464/60000]\n",
      "loss: 0.994616  [44864/60000]\n",
      "loss: 1.162681  [51264/60000]\n",
      "loss: 1.150312  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 1.101014 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.027814  [   64/60000]\n",
      "loss: 1.000091  [ 6464/60000]\n",
      "loss: 0.990814  [12864/60000]\n",
      "loss: 0.983009  [19264/60000]\n",
      "loss: 0.955716  [25664/60000]\n",
      "loss: 0.932735  [32064/60000]\n",
      "loss: 0.861907  [38464/60000]\n",
      "loss: 1.082075  [44864/60000]\n",
      "loss: 0.978427  [51264/60000]\n",
      "loss: 0.968820  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.986072 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.833866  [   64/60000]\n",
      "loss: 1.019256  [ 6464/60000]\n",
      "loss: 0.983401  [12864/60000]\n",
      "loss: 0.881140  [19264/60000]\n",
      "loss: 0.878618  [25664/60000]\n",
      "loss: 0.989899  [32064/60000]\n",
      "loss: 0.929075  [38464/60000]\n",
      "loss: 0.892306  [44864/60000]\n",
      "loss: 0.821830  [51264/60000]\n",
      "loss: 0.946572  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.909826 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.925532  [   64/60000]\n",
      "loss: 0.990713  [ 6464/60000]\n",
      "loss: 0.828975  [12864/60000]\n",
      "loss: 0.893257  [19264/60000]\n",
      "loss: 0.900382  [25664/60000]\n",
      "loss: 0.881218  [32064/60000]\n",
      "loss: 0.872402  [38464/60000]\n",
      "loss: 0.886215  [44864/60000]\n",
      "loss: 0.707004  [51264/60000]\n",
      "loss: 0.810526  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.857960 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.899855  [   64/60000]\n",
      "loss: 0.845958  [ 6464/60000]\n",
      "loss: 0.734564  [12864/60000]\n",
      "loss: 0.744540  [19264/60000]\n",
      "loss: 0.902694  [25664/60000]\n",
      "loss: 0.765148  [32064/60000]\n",
      "loss: 0.662695  [38464/60000]\n",
      "loss: 0.900506  [44864/60000]\n",
      "loss: 0.693988  [51264/60000]\n",
      "loss: 0.784510  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.818502 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.004526  [   64/60000]\n",
      "loss: 0.813088  [ 6464/60000]\n",
      "loss: 0.801409  [12864/60000]\n",
      "loss: 0.758419  [19264/60000]\n",
      "loss: 0.823173  [25664/60000]\n",
      "loss: 0.771755  [32064/60000]\n",
      "loss: 0.717861  [38464/60000]\n",
      "loss: 0.918349  [44864/60000]\n",
      "loss: 0.839937  [51264/60000]\n",
      "loss: 0.678205  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.789382 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.847093  [   64/60000]\n",
      "loss: 0.745402  [ 6464/60000]\n",
      "loss: 0.760830  [12864/60000]\n",
      "loss: 0.890984  [19264/60000]\n",
      "loss: 0.837588  [25664/60000]\n",
      "loss: 1.135992  [32064/60000]\n",
      "loss: 0.857223  [38464/60000]\n",
      "loss: 0.993419  [44864/60000]\n",
      "loss: 0.599004  [51264/60000]\n",
      "loss: 0.722167  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.761563 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.786666  [   64/60000]\n",
      "loss: 0.699043  [ 6464/60000]\n",
      "loss: 0.822255  [12864/60000]\n",
      "loss: 0.688625  [19264/60000]\n",
      "loss: 0.626388  [25664/60000]\n",
      "loss: 0.849042  [32064/60000]\n",
      "loss: 0.790252  [38464/60000]\n",
      "loss: 0.746612  [44864/60000]\n",
      "loss: 0.739381  [51264/60000]\n",
      "loss: 0.717662  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.741126 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.901815  [   64/60000]\n",
      "loss: 0.781621  [ 6464/60000]\n",
      "loss: 0.728851  [12864/60000]\n",
      "loss: 0.618753  [19264/60000]\n",
      "loss: 0.701895  [25664/60000]\n",
      "loss: 0.637537  [32064/60000]\n",
      "loss: 0.602104  [38464/60000]\n",
      "loss: 0.834972  [44864/60000]\n",
      "loss: 0.619205  [51264/60000]\n",
      "loss: 0.677943  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.722870 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.779806  [   64/60000]\n",
      "loss: 0.643038  [ 6464/60000]\n",
      "loss: 0.635505  [12864/60000]\n",
      "loss: 0.568559  [19264/60000]\n",
      "loss: 0.598350  [25664/60000]\n",
      "loss: 0.654325  [32064/60000]\n",
      "loss: 0.746313  [38464/60000]\n",
      "loss: 0.593964  [44864/60000]\n",
      "loss: 0.815469  [51264/60000]\n",
      "loss: 0.582138  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.706043 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.733634  [   64/60000]\n",
      "loss: 0.636145  [ 6464/60000]\n",
      "loss: 0.643499  [12864/60000]\n",
      "loss: 0.638684  [19264/60000]\n",
      "loss: 0.650634  [25664/60000]\n",
      "loss: 0.649303  [32064/60000]\n",
      "loss: 0.689164  [38464/60000]\n",
      "loss: 0.495951  [44864/60000]\n",
      "loss: 0.687606  [51264/60000]\n",
      "loss: 0.540725  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.689219 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.578491  [   64/60000]\n",
      "loss: 0.588602  [ 6464/60000]\n",
      "loss: 0.557857  [12864/60000]\n",
      "loss: 0.653834  [19264/60000]\n",
      "loss: 0.620860  [25664/60000]\n",
      "loss: 0.519296  [32064/60000]\n",
      "loss: 0.648724  [38464/60000]\n",
      "loss: 0.871069  [44864/60000]\n",
      "loss: 0.616242  [51264/60000]\n",
      "loss: 0.575439  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.674667 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.810037  [   64/60000]\n",
      "loss: 1.041955  [ 6464/60000]\n",
      "loss: 0.734435  [12864/60000]\n",
      "loss: 0.658745  [19264/60000]\n",
      "loss: 0.599019  [25664/60000]\n",
      "loss: 0.704522  [32064/60000]\n",
      "loss: 0.586079  [38464/60000]\n",
      "loss: 0.576932  [44864/60000]\n",
      "loss: 0.639895  [51264/60000]\n",
      "loss: 0.633513  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.662241 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.733343  [   64/60000]\n",
      "loss: 0.618769  [ 6464/60000]\n",
      "loss: 0.525391  [12864/60000]\n",
      "loss: 0.758216  [19264/60000]\n",
      "loss: 0.695503  [25664/60000]\n",
      "loss: 0.513389  [32064/60000]\n",
      "loss: 0.624555  [38464/60000]\n",
      "loss: 0.678084  [44864/60000]\n",
      "loss: 0.945906  [51264/60000]\n",
      "loss: 0.452355  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.649673 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.554473  [   64/60000]\n",
      "loss: 0.794636  [ 6464/60000]\n",
      "loss: 0.513254  [12864/60000]\n",
      "loss: 0.637101  [19264/60000]\n",
      "loss: 0.590756  [25664/60000]\n",
      "loss: 0.540154  [32064/60000]\n",
      "loss: 0.477616  [38464/60000]\n",
      "loss: 0.731380  [44864/60000]\n",
      "loss: 0.555277  [51264/60000]\n",
      "loss: 0.706441  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.636148 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.689255  [   64/60000]\n",
      "loss: 0.646484  [ 6464/60000]\n",
      "loss: 0.632523  [12864/60000]\n",
      "loss: 0.546836  [19264/60000]\n",
      "loss: 0.848497  [25664/60000]\n",
      "loss: 0.577244  [32064/60000]\n",
      "loss: 0.559701  [38464/60000]\n",
      "loss: 0.552564  [44864/60000]\n",
      "loss: 0.393794  [51264/60000]\n",
      "loss: 0.518873  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.626961 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.674781  [   64/60000]\n",
      "loss: 0.726765  [ 6464/60000]\n",
      "loss: 0.424264  [12864/60000]\n",
      "loss: 0.594188  [19264/60000]\n",
      "loss: 0.672536  [25664/60000]\n",
      "loss: 0.570045  [32064/60000]\n",
      "loss: 0.422466  [38464/60000]\n",
      "loss: 0.548070  [44864/60000]\n",
      "loss: 0.819756  [51264/60000]\n",
      "loss: 0.609603  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.615202 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.770761  [   64/60000]\n",
      "loss: 0.574818  [ 6464/60000]\n",
      "loss: 0.514253  [12864/60000]\n",
      "loss: 0.488667  [19264/60000]\n",
      "loss: 0.595395  [25664/60000]\n",
      "loss: 0.559618  [32064/60000]\n",
      "loss: 0.777944  [38464/60000]\n",
      "loss: 0.733934  [44864/60000]\n",
      "loss: 0.666128  [51264/60000]\n",
      "loss: 0.600410  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.606483 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.529946  [   64/60000]\n",
      "loss: 0.515481  [ 6464/60000]\n",
      "loss: 0.577329  [12864/60000]\n",
      "loss: 0.621101  [19264/60000]\n",
      "loss: 0.563758  [25664/60000]\n",
      "loss: 0.679722  [32064/60000]\n",
      "loss: 0.689649  [38464/60000]\n",
      "loss: 0.600990  [44864/60000]\n",
      "loss: 0.563850  [51264/60000]\n",
      "loss: 0.659927  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.599735 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.563758  [   64/60000]\n",
      "loss: 0.679116  [ 6464/60000]\n",
      "loss: 0.618499  [12864/60000]\n",
      "loss: 0.593266  [19264/60000]\n",
      "loss: 0.748057  [25664/60000]\n",
      "loss: 0.581333  [32064/60000]\n",
      "loss: 0.511673  [38464/60000]\n",
      "loss: 0.713700  [44864/60000]\n",
      "loss: 0.636341  [51264/60000]\n",
      "loss: 0.469122  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.590075 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.565298  [   64/60000]\n",
      "loss: 0.476219  [ 6464/60000]\n",
      "loss: 0.653223  [12864/60000]\n",
      "loss: 0.506639  [19264/60000]\n",
      "loss: 0.518642  [25664/60000]\n",
      "loss: 0.517833  [32064/60000]\n",
      "loss: 0.523730  [38464/60000]\n",
      "loss: 0.714312  [44864/60000]\n",
      "loss: 0.630257  [51264/60000]\n",
      "loss: 0.614193  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.583943 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.585094  [   64/60000]\n",
      "loss: 0.601482  [ 6464/60000]\n",
      "loss: 0.512507  [12864/60000]\n",
      "loss: 0.560336  [19264/60000]\n",
      "loss: 0.582824  [25664/60000]\n",
      "loss: 0.629225  [32064/60000]\n",
      "loss: 0.467158  [38464/60000]\n",
      "loss: 0.471989  [44864/60000]\n",
      "loss: 0.402653  [51264/60000]\n",
      "loss: 0.405278  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.574916 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.504993  [   64/60000]\n",
      "loss: 0.539996  [ 6464/60000]\n",
      "loss: 0.612603  [12864/60000]\n",
      "loss: 0.433509  [19264/60000]\n",
      "loss: 0.430362  [25664/60000]\n",
      "loss: 0.515201  [32064/60000]\n",
      "loss: 0.514075  [38464/60000]\n",
      "loss: 0.583366  [44864/60000]\n",
      "loss: 0.663024  [51264/60000]\n",
      "loss: 0.346962  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.567827 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.662820  [   64/60000]\n",
      "loss: 0.677741  [ 6464/60000]\n",
      "loss: 0.356815  [12864/60000]\n",
      "loss: 0.651981  [19264/60000]\n",
      "loss: 0.554415  [25664/60000]\n",
      "loss: 0.765307  [32064/60000]\n",
      "loss: 0.370017  [38464/60000]\n",
      "loss: 0.513814  [44864/60000]\n",
      "loss: 0.457710  [51264/60000]\n",
      "loss: 0.546009  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.565860 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.489683  [   64/60000]\n",
      "loss: 0.711005  [ 6464/60000]\n",
      "loss: 0.714005  [12864/60000]\n",
      "loss: 0.537713  [19264/60000]\n",
      "loss: 0.631221  [25664/60000]\n",
      "loss: 0.356562  [32064/60000]\n",
      "loss: 0.436218  [38464/60000]\n",
      "loss: 0.418943  [44864/60000]\n",
      "loss: 0.572796  [51264/60000]\n",
      "loss: 0.496954  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.557491 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.633719  [   64/60000]\n",
      "loss: 0.460849  [ 6464/60000]\n",
      "loss: 0.497683  [12864/60000]\n",
      "loss: 0.730541  [19264/60000]\n",
      "loss: 0.510101  [25664/60000]\n",
      "loss: 0.616405  [32064/60000]\n",
      "loss: 0.470335  [38464/60000]\n",
      "loss: 0.813428  [44864/60000]\n",
      "loss: 0.576177  [51264/60000]\n",
      "loss: 0.622012  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.552079 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.570885  [   64/60000]\n",
      "loss: 0.497668  [ 6464/60000]\n",
      "loss: 0.362692  [12864/60000]\n",
      "loss: 0.376972  [19264/60000]\n",
      "loss: 0.431448  [25664/60000]\n",
      "loss: 0.339088  [32064/60000]\n",
      "loss: 0.676478  [38464/60000]\n",
      "loss: 0.563016  [44864/60000]\n",
      "loss: 0.367607  [51264/60000]\n",
      "loss: 0.653668  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.548655 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.438573  [   64/60000]\n",
      "loss: 0.325972  [ 6464/60000]\n",
      "loss: 0.565655  [12864/60000]\n",
      "loss: 0.507870  [19264/60000]\n",
      "loss: 0.695854  [25664/60000]\n",
      "loss: 0.644619  [32064/60000]\n",
      "loss: 0.453732  [38464/60000]\n",
      "loss: 0.462094  [44864/60000]\n",
      "loss: 0.604535  [51264/60000]\n",
      "loss: 0.361737  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.541502 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.686448  [   64/60000]\n",
      "loss: 0.358375  [ 6464/60000]\n",
      "loss: 0.576995  [12864/60000]\n",
      "loss: 0.481212  [19264/60000]\n",
      "loss: 0.480235  [25664/60000]\n",
      "loss: 0.556946  [32064/60000]\n",
      "loss: 0.664907  [38464/60000]\n",
      "loss: 0.444182  [44864/60000]\n",
      "loss: 0.556072  [51264/60000]\n",
      "loss: 0.418416  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.535855 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.575218  [   64/60000]\n",
      "loss: 0.394729  [ 6464/60000]\n",
      "loss: 0.596435  [12864/60000]\n",
      "loss: 0.416936  [19264/60000]\n",
      "loss: 0.435068  [25664/60000]\n",
      "loss: 0.533186  [32064/60000]\n",
      "loss: 0.332152  [38464/60000]\n",
      "loss: 0.329301  [44864/60000]\n",
      "loss: 0.618731  [51264/60000]\n",
      "loss: 0.424186  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.533391 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.334029  [   64/60000]\n",
      "loss: 0.557830  [ 6464/60000]\n",
      "loss: 0.406576  [12864/60000]\n",
      "loss: 0.358363  [19264/60000]\n",
      "loss: 0.544554  [25664/60000]\n",
      "loss: 0.421427  [32064/60000]\n",
      "loss: 0.455877  [38464/60000]\n",
      "loss: 0.524853  [44864/60000]\n",
      "loss: 0.560428  [51264/60000]\n",
      "loss: 0.487665  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.532095 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.476809  [   64/60000]\n",
      "loss: 0.552603  [ 6464/60000]\n",
      "loss: 0.365315  [12864/60000]\n",
      "loss: 0.719099  [19264/60000]\n",
      "loss: 0.541987  [25664/60000]\n",
      "loss: 0.562838  [32064/60000]\n",
      "loss: 0.326803  [38464/60000]\n",
      "loss: 0.651814  [44864/60000]\n",
      "loss: 0.358137  [51264/60000]\n",
      "loss: 0.482769  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.525338 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.397810  [   64/60000]\n",
      "loss: 0.653855  [ 6464/60000]\n",
      "loss: 0.599154  [12864/60000]\n",
      "loss: 0.513365  [19264/60000]\n",
      "loss: 0.670339  [25664/60000]\n",
      "loss: 0.448934  [32064/60000]\n",
      "loss: 0.413366  [38464/60000]\n",
      "loss: 0.489701  [44864/60000]\n",
      "loss: 0.522280  [51264/60000]\n",
      "loss: 0.439866  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.522482 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.393871  [   64/60000]\n",
      "loss: 0.474157  [ 6464/60000]\n",
      "loss: 0.436562  [12864/60000]\n",
      "loss: 0.629095  [19264/60000]\n",
      "loss: 0.308736  [25664/60000]\n",
      "loss: 0.536118  [32064/60000]\n",
      "loss: 0.508462  [38464/60000]\n",
      "loss: 0.468355  [44864/60000]\n",
      "loss: 0.359017  [51264/60000]\n",
      "loss: 0.477759  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.521016 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.573992  [   64/60000]\n",
      "loss: 0.343999  [ 6464/60000]\n",
      "loss: 0.520107  [12864/60000]\n",
      "loss: 0.558105  [19264/60000]\n",
      "loss: 0.595379  [25664/60000]\n",
      "loss: 0.469577  [32064/60000]\n",
      "loss: 0.621111  [38464/60000]\n",
      "loss: 0.443497  [44864/60000]\n",
      "loss: 0.463184  [51264/60000]\n",
      "loss: 0.701454  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.517339 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.436444  [   64/60000]\n",
      "loss: 0.499724  [ 6464/60000]\n",
      "loss: 0.299056  [12864/60000]\n",
      "loss: 0.465718  [19264/60000]\n",
      "loss: 0.657888  [25664/60000]\n",
      "loss: 0.587519  [32064/60000]\n",
      "loss: 0.526006  [38464/60000]\n",
      "loss: 0.500691  [44864/60000]\n",
      "loss: 0.545336  [51264/60000]\n",
      "loss: 0.396304  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.513621 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.313912  [   64/60000]\n",
      "loss: 0.349058  [ 6464/60000]\n",
      "loss: 0.433650  [12864/60000]\n",
      "loss: 0.591390  [19264/60000]\n",
      "loss: 0.398089  [25664/60000]\n",
      "loss: 0.490372  [32064/60000]\n",
      "loss: 0.411168  [38464/60000]\n",
      "loss: 0.434250  [44864/60000]\n",
      "loss: 0.860213  [51264/60000]\n",
      "loss: 0.447609  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.510262 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.432018  [   64/60000]\n",
      "loss: 0.412437  [ 6464/60000]\n",
      "loss: 0.490105  [12864/60000]\n",
      "loss: 0.331960  [19264/60000]\n",
      "loss: 0.712305  [25664/60000]\n",
      "loss: 0.387334  [32064/60000]\n",
      "loss: 0.449822  [38464/60000]\n",
      "loss: 0.425031  [44864/60000]\n",
      "loss: 0.495417  [51264/60000]\n",
      "loss: 0.372057  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.506476 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.376386  [   64/60000]\n",
      "loss: 0.376275  [ 6464/60000]\n",
      "loss: 0.398384  [12864/60000]\n",
      "loss: 0.567333  [19264/60000]\n",
      "loss: 0.737985  [25664/60000]\n",
      "loss: 0.408425  [32064/60000]\n",
      "loss: 0.342632  [38464/60000]\n",
      "loss: 0.500586  [44864/60000]\n",
      "loss: 0.474488  [51264/60000]\n",
      "loss: 0.486561  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.506146 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.426576  [   64/60000]\n",
      "loss: 0.656407  [ 6464/60000]\n",
      "loss: 0.522805  [12864/60000]\n",
      "loss: 0.441520  [19264/60000]\n",
      "loss: 0.351094  [25664/60000]\n",
      "loss: 0.399060  [32064/60000]\n",
      "loss: 0.483335  [38464/60000]\n",
      "loss: 0.413700  [44864/60000]\n",
      "loss: 0.699819  [51264/60000]\n",
      "loss: 0.394045  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.504328 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.411861  [   64/60000]\n",
      "loss: 0.596543  [ 6464/60000]\n",
      "loss: 0.463057  [12864/60000]\n",
      "loss: 0.356990  [19264/60000]\n",
      "loss: 0.401779  [25664/60000]\n",
      "loss: 0.638618  [32064/60000]\n",
      "loss: 0.351482  [38464/60000]\n",
      "loss: 0.377106  [44864/60000]\n",
      "loss: 0.330660  [51264/60000]\n",
      "loss: 0.399273  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.499990 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.433145  [   64/60000]\n",
      "loss: 0.472320  [ 6464/60000]\n",
      "loss: 0.542851  [12864/60000]\n",
      "loss: 0.664099  [19264/60000]\n",
      "loss: 0.365835  [25664/60000]\n",
      "loss: 0.400898  [32064/60000]\n",
      "loss: 0.399669  [38464/60000]\n",
      "loss: 0.503519  [44864/60000]\n",
      "loss: 0.314512  [51264/60000]\n",
      "loss: 0.297096  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.499431 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.598314  [   64/60000]\n",
      "loss: 0.531140  [ 6464/60000]\n",
      "loss: 0.364166  [12864/60000]\n",
      "loss: 0.618342  [19264/60000]\n",
      "loss: 0.572757  [25664/60000]\n",
      "loss: 0.397794  [32064/60000]\n",
      "loss: 0.384590  [38464/60000]\n",
      "loss: 0.421750  [44864/60000]\n",
      "loss: 0.339960  [51264/60000]\n",
      "loss: 0.426664  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.500935 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.438944  [   64/60000]\n",
      "loss: 0.502520  [ 6464/60000]\n",
      "loss: 0.365380  [12864/60000]\n",
      "loss: 0.466276  [19264/60000]\n",
      "loss: 0.516707  [25664/60000]\n",
      "loss: 0.608161  [32064/60000]\n",
      "loss: 0.472865  [38464/60000]\n",
      "loss: 0.452361  [44864/60000]\n",
      "loss: 0.315018  [51264/60000]\n",
      "loss: 0.390933  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.494185 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.307946  [   64/60000]\n",
      "loss: 0.479370  [ 6464/60000]\n",
      "loss: 0.360551  [12864/60000]\n",
      "loss: 0.418000  [19264/60000]\n",
      "loss: 0.553047  [25664/60000]\n",
      "loss: 0.581512  [32064/60000]\n",
      "loss: 0.435124  [38464/60000]\n",
      "loss: 0.457437  [44864/60000]\n",
      "loss: 0.431862  [51264/60000]\n",
      "loss: 0.603967  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.492256 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.280981  [   64/60000]\n",
      "loss: 0.506792  [ 6464/60000]\n",
      "loss: 0.551267  [12864/60000]\n",
      "loss: 0.509847  [19264/60000]\n",
      "loss: 0.377793  [25664/60000]\n",
      "loss: 0.481132  [32064/60000]\n",
      "loss: 0.508422  [38464/60000]\n",
      "loss: 0.401348  [44864/60000]\n",
      "loss: 0.843980  [51264/60000]\n",
      "loss: 0.406212  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.490883 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.382560  [   64/60000]\n",
      "loss: 0.618537  [ 6464/60000]\n",
      "loss: 0.425437  [12864/60000]\n",
      "loss: 0.253640  [19264/60000]\n",
      "loss: 0.419895  [25664/60000]\n",
      "loss: 0.845419  [32064/60000]\n",
      "loss: 0.461365  [38464/60000]\n",
      "loss: 0.500817  [44864/60000]\n",
      "loss: 0.475627  [51264/60000]\n",
      "loss: 0.441467  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.491305 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.412262  [   64/60000]\n",
      "loss: 0.465777  [ 6464/60000]\n",
      "loss: 0.465971  [12864/60000]\n",
      "loss: 0.605554  [19264/60000]\n",
      "loss: 0.308452  [25664/60000]\n",
      "loss: 0.524090  [32064/60000]\n",
      "loss: 0.489352  [38464/60000]\n",
      "loss: 0.406680  [44864/60000]\n",
      "loss: 0.462777  [51264/60000]\n",
      "loss: 0.358613  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.489496 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.420583  [   64/60000]\n",
      "loss: 0.527346  [ 6464/60000]\n",
      "loss: 0.471339  [12864/60000]\n",
      "loss: 0.422064  [19264/60000]\n",
      "loss: 0.517365  [25664/60000]\n",
      "loss: 0.325773  [32064/60000]\n",
      "loss: 0.553999  [38464/60000]\n",
      "loss: 0.602301  [44864/60000]\n",
      "loss: 0.498264  [51264/60000]\n",
      "loss: 0.536011  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.485995 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.454266  [   64/60000]\n",
      "loss: 0.522276  [ 6464/60000]\n",
      "loss: 0.462406  [12864/60000]\n",
      "loss: 0.348099  [19264/60000]\n",
      "loss: 0.439925  [25664/60000]\n",
      "loss: 0.292964  [32064/60000]\n",
      "loss: 0.546202  [38464/60000]\n",
      "loss: 0.406998  [44864/60000]\n",
      "loss: 0.308872  [51264/60000]\n",
      "loss: 0.573307  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.485645 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.352258  [   64/60000]\n",
      "loss: 0.565688  [ 6464/60000]\n",
      "loss: 0.330207  [12864/60000]\n",
      "loss: 0.427508  [19264/60000]\n",
      "loss: 0.578771  [25664/60000]\n",
      "loss: 0.618834  [32064/60000]\n",
      "loss: 0.474897  [38464/60000]\n",
      "loss: 0.640845  [44864/60000]\n",
      "loss: 0.328812  [51264/60000]\n",
      "loss: 0.273914  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.483271 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.372089  [   64/60000]\n",
      "loss: 0.401789  [ 6464/60000]\n",
      "loss: 0.457468  [12864/60000]\n",
      "loss: 0.629902  [19264/60000]\n",
      "loss: 0.502242  [25664/60000]\n",
      "loss: 0.491491  [32064/60000]\n",
      "loss: 0.570047  [38464/60000]\n",
      "loss: 0.372019  [44864/60000]\n",
      "loss: 0.523677  [51264/60000]\n",
      "loss: 0.473523  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.483632 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.599214  [   64/60000]\n",
      "loss: 0.336876  [ 6464/60000]\n",
      "loss: 0.501695  [12864/60000]\n",
      "loss: 0.572065  [19264/60000]\n",
      "loss: 0.399577  [25664/60000]\n",
      "loss: 0.448819  [32064/60000]\n",
      "loss: 0.306815  [38464/60000]\n",
      "loss: 0.487740  [44864/60000]\n",
      "loss: 0.506560  [51264/60000]\n",
      "loss: 0.410625  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.478863 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.296534  [   64/60000]\n",
      "loss: 0.343449  [ 6464/60000]\n",
      "loss: 0.567268  [12864/60000]\n",
      "loss: 0.541524  [19264/60000]\n",
      "loss: 0.339595  [25664/60000]\n",
      "loss: 0.467354  [32064/60000]\n",
      "loss: 0.234194  [38464/60000]\n",
      "loss: 0.375914  [44864/60000]\n",
      "loss: 0.586886  [51264/60000]\n",
      "loss: 0.327804  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.478856 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.443026  [   64/60000]\n",
      "loss: 0.440054  [ 6464/60000]\n",
      "loss: 0.416023  [12864/60000]\n",
      "loss: 0.399968  [19264/60000]\n",
      "loss: 0.260164  [25664/60000]\n",
      "loss: 0.473600  [32064/60000]\n",
      "loss: 0.550614  [38464/60000]\n",
      "loss: 0.594612  [44864/60000]\n",
      "loss: 0.586799  [51264/60000]\n",
      "loss: 0.330156  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.475452 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.488585  [   64/60000]\n",
      "loss: 0.403634  [ 6464/60000]\n",
      "loss: 0.427740  [12864/60000]\n",
      "loss: 0.459599  [19264/60000]\n",
      "loss: 0.483079  [25664/60000]\n",
      "loss: 0.780866  [32064/60000]\n",
      "loss: 0.545560  [38464/60000]\n",
      "loss: 0.374090  [44864/60000]\n",
      "loss: 0.562106  [51264/60000]\n",
      "loss: 0.375848  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.475360 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.547303  [   64/60000]\n",
      "loss: 0.389527  [ 6464/60000]\n",
      "loss: 0.469627  [12864/60000]\n",
      "loss: 0.328055  [19264/60000]\n",
      "loss: 0.324220  [25664/60000]\n",
      "loss: 0.484945  [32064/60000]\n",
      "loss: 0.432683  [38464/60000]\n",
      "loss: 0.723616  [44864/60000]\n",
      "loss: 0.315615  [51264/60000]\n",
      "loss: 0.394240  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.474589 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.260847  [   64/60000]\n",
      "loss: 0.485240  [ 6464/60000]\n",
      "loss: 0.424287  [12864/60000]\n",
      "loss: 0.244903  [19264/60000]\n",
      "loss: 0.309309  [25664/60000]\n",
      "loss: 0.556197  [32064/60000]\n",
      "loss: 0.439923  [38464/60000]\n",
      "loss: 0.423132  [44864/60000]\n",
      "loss: 0.405991  [51264/60000]\n",
      "loss: 0.458847  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.474282 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.471250  [   64/60000]\n",
      "loss: 0.514703  [ 6464/60000]\n",
      "loss: 0.431794  [12864/60000]\n",
      "loss: 0.545656  [19264/60000]\n",
      "loss: 0.324466  [25664/60000]\n",
      "loss: 0.341756  [32064/60000]\n",
      "loss: 0.371743  [38464/60000]\n",
      "loss: 0.381682  [44864/60000]\n",
      "loss: 0.383472  [51264/60000]\n",
      "loss: 0.438413  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.472544 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.574300  [   64/60000]\n",
      "loss: 0.419955  [ 6464/60000]\n",
      "loss: 0.378205  [12864/60000]\n",
      "loss: 0.401229  [19264/60000]\n",
      "loss: 0.349300  [25664/60000]\n",
      "loss: 0.561474  [32064/60000]\n",
      "loss: 0.425439  [38464/60000]\n",
      "loss: 0.266683  [44864/60000]\n",
      "loss: 0.536188  [51264/60000]\n",
      "loss: 0.420761  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.470687 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.636690  [   64/60000]\n",
      "loss: 0.440301  [ 6464/60000]\n",
      "loss: 0.432487  [12864/60000]\n",
      "loss: 0.647344  [19264/60000]\n",
      "loss: 0.265977  [25664/60000]\n",
      "loss: 0.357381  [32064/60000]\n",
      "loss: 0.372496  [38464/60000]\n",
      "loss: 0.430391  [44864/60000]\n",
      "loss: 0.448451  [51264/60000]\n",
      "loss: 0.432044  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.468122 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.628301  [   64/60000]\n",
      "loss: 0.485679  [ 6464/60000]\n",
      "loss: 0.328915  [12864/60000]\n",
      "loss: 0.414655  [19264/60000]\n",
      "loss: 0.502614  [25664/60000]\n",
      "loss: 0.359501  [32064/60000]\n",
      "loss: 0.301534  [38464/60000]\n",
      "loss: 0.314348  [44864/60000]\n",
      "loss: 0.357477  [51264/60000]\n",
      "loss: 0.679943  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.468936 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.394503  [   64/60000]\n",
      "loss: 0.364361  [ 6464/60000]\n",
      "loss: 0.609966  [12864/60000]\n",
      "loss: 0.332326  [19264/60000]\n",
      "loss: 0.459189  [25664/60000]\n",
      "loss: 0.701312  [32064/60000]\n",
      "loss: 0.481950  [38464/60000]\n",
      "loss: 0.450759  [44864/60000]\n",
      "loss: 0.392732  [51264/60000]\n",
      "loss: 0.245360  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.465607 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.296973  [   64/60000]\n",
      "loss: 0.372917  [ 6464/60000]\n",
      "loss: 0.432761  [12864/60000]\n",
      "loss: 0.366593  [19264/60000]\n",
      "loss: 0.496163  [25664/60000]\n",
      "loss: 0.482944  [32064/60000]\n",
      "loss: 0.437776  [38464/60000]\n",
      "loss: 0.422937  [44864/60000]\n",
      "loss: 0.309859  [51264/60000]\n",
      "loss: 0.403795  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.465965 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.617847  [   64/60000]\n",
      "loss: 0.475325  [ 6464/60000]\n",
      "loss: 0.555610  [12864/60000]\n",
      "loss: 0.476031  [19264/60000]\n",
      "loss: 0.407626  [25664/60000]\n",
      "loss: 0.293271  [32064/60000]\n",
      "loss: 0.373055  [38464/60000]\n",
      "loss: 0.512801  [44864/60000]\n",
      "loss: 0.330615  [51264/60000]\n",
      "loss: 0.475602  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.467291 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.362414  [   64/60000]\n",
      "loss: 0.383044  [ 6464/60000]\n",
      "loss: 0.280194  [12864/60000]\n",
      "loss: 0.379920  [19264/60000]\n",
      "loss: 0.347734  [25664/60000]\n",
      "loss: 0.451829  [32064/60000]\n",
      "loss: 0.391612  [38464/60000]\n",
      "loss: 0.434295  [44864/60000]\n",
      "loss: 0.348875  [51264/60000]\n",
      "loss: 0.471148  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.463251 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.390434  [   64/60000]\n",
      "loss: 0.437276  [ 6464/60000]\n",
      "loss: 0.280914  [12864/60000]\n",
      "loss: 0.419146  [19264/60000]\n",
      "loss: 0.251983  [25664/60000]\n",
      "loss: 0.388754  [32064/60000]\n",
      "loss: 0.421455  [38464/60000]\n",
      "loss: 0.474695  [44864/60000]\n",
      "loss: 0.351102  [51264/60000]\n",
      "loss: 0.559934  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.462560 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.512128  [   64/60000]\n",
      "loss: 0.481700  [ 6464/60000]\n",
      "loss: 0.482184  [12864/60000]\n",
      "loss: 0.455325  [19264/60000]\n",
      "loss: 0.317694  [25664/60000]\n",
      "loss: 0.466504  [32064/60000]\n",
      "loss: 0.449420  [38464/60000]\n",
      "loss: 0.361384  [44864/60000]\n",
      "loss: 0.479298  [51264/60000]\n",
      "loss: 0.562157  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.462265 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.467800  [   64/60000]\n",
      "loss: 0.279916  [ 6464/60000]\n",
      "loss: 0.386000  [12864/60000]\n",
      "loss: 0.410094  [19264/60000]\n",
      "loss: 0.299969  [25664/60000]\n",
      "loss: 0.456751  [32064/60000]\n",
      "loss: 0.345837  [38464/60000]\n",
      "loss: 0.463823  [44864/60000]\n",
      "loss: 0.407923  [51264/60000]\n",
      "loss: 0.389543  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.462343 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.415718  [   64/60000]\n",
      "loss: 0.306924  [ 6464/60000]\n",
      "loss: 0.327501  [12864/60000]\n",
      "loss: 0.450203  [19264/60000]\n",
      "loss: 0.701223  [25664/60000]\n",
      "loss: 0.242580  [32064/60000]\n",
      "loss: 0.321718  [38464/60000]\n",
      "loss: 0.308475  [44864/60000]\n",
      "loss: 0.496829  [51264/60000]\n",
      "loss: 0.296647  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.457343 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.357072  [   64/60000]\n",
      "loss: 0.228988  [ 6464/60000]\n",
      "loss: 0.297065  [12864/60000]\n",
      "loss: 0.378151  [19264/60000]\n",
      "loss: 0.266510  [25664/60000]\n",
      "loss: 0.396428  [32064/60000]\n",
      "loss: 0.368592  [38464/60000]\n",
      "loss: 0.394878  [44864/60000]\n",
      "loss: 0.475165  [51264/60000]\n",
      "loss: 0.373747  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.457662 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.521755  [   64/60000]\n",
      "loss: 0.490127  [ 6464/60000]\n",
      "loss: 0.261985  [12864/60000]\n",
      "loss: 0.352094  [19264/60000]\n",
      "loss: 0.525922  [25664/60000]\n",
      "loss: 0.387374  [32064/60000]\n",
      "loss: 0.414670  [38464/60000]\n",
      "loss: 0.423133  [44864/60000]\n",
      "loss: 0.602217  [51264/60000]\n",
      "loss: 0.346078  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.455295 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.372371  [   64/60000]\n",
      "loss: 0.337938  [ 6464/60000]\n",
      "loss: 0.668902  [12864/60000]\n",
      "loss: 0.429895  [19264/60000]\n",
      "loss: 0.389913  [25664/60000]\n",
      "loss: 0.354068  [32064/60000]\n",
      "loss: 0.734278  [38464/60000]\n",
      "loss: 0.575707  [44864/60000]\n",
      "loss: 0.284606  [51264/60000]\n",
      "loss: 0.393497  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.459075 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.412419  [   64/60000]\n",
      "loss: 0.386326  [ 6464/60000]\n",
      "loss: 0.365518  [12864/60000]\n",
      "loss: 0.308252  [19264/60000]\n",
      "loss: 0.446866  [25664/60000]\n",
      "loss: 0.423227  [32064/60000]\n",
      "loss: 0.306156  [38464/60000]\n",
      "loss: 0.469433  [44864/60000]\n",
      "loss: 0.294766  [51264/60000]\n",
      "loss: 0.375433  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.454409 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.258197  [   64/60000]\n",
      "loss: 0.475440  [ 6464/60000]\n",
      "loss: 0.327073  [12864/60000]\n",
      "loss: 0.368333  [19264/60000]\n",
      "loss: 0.364893  [25664/60000]\n",
      "loss: 0.367996  [32064/60000]\n",
      "loss: 0.434368  [38464/60000]\n",
      "loss: 0.327150  [44864/60000]\n",
      "loss: 0.327427  [51264/60000]\n",
      "loss: 0.256955  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.453574 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.309544  [   64/60000]\n",
      "loss: 0.382739  [ 6464/60000]\n",
      "loss: 0.347550  [12864/60000]\n",
      "loss: 0.615272  [19264/60000]\n",
      "loss: 0.332900  [25664/60000]\n",
      "loss: 0.341686  [32064/60000]\n",
      "loss: 0.451420  [38464/60000]\n",
      "loss: 0.374028  [44864/60000]\n",
      "loss: 0.416004  [51264/60000]\n",
      "loss: 0.417712  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.457415 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.434806  [   64/60000]\n",
      "loss: 0.460111  [ 6464/60000]\n",
      "loss: 0.376406  [12864/60000]\n",
      "loss: 0.496373  [19264/60000]\n",
      "loss: 0.353964  [25664/60000]\n",
      "loss: 0.355312  [32064/60000]\n",
      "loss: 0.294660  [38464/60000]\n",
      "loss: 0.347056  [44864/60000]\n",
      "loss: 0.376375  [51264/60000]\n",
      "loss: 0.629114  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.453159 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.547238  [   64/60000]\n",
      "loss: 0.486832  [ 6464/60000]\n",
      "loss: 0.649265  [12864/60000]\n",
      "loss: 0.414227  [19264/60000]\n",
      "loss: 0.520085  [25664/60000]\n",
      "loss: 0.356173  [32064/60000]\n",
      "loss: 0.337657  [38464/60000]\n",
      "loss: 0.570067  [44864/60000]\n",
      "loss: 0.508950  [51264/60000]\n",
      "loss: 0.345169  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.450389 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.474816  [   64/60000]\n",
      "loss: 0.289548  [ 6464/60000]\n",
      "loss: 0.287691  [12864/60000]\n",
      "loss: 0.364789  [19264/60000]\n",
      "loss: 0.479832  [25664/60000]\n",
      "loss: 0.279151  [32064/60000]\n",
      "loss: 0.330064  [38464/60000]\n",
      "loss: 0.387590  [44864/60000]\n",
      "loss: 0.305173  [51264/60000]\n",
      "loss: 0.496782  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.449720 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.359602  [   64/60000]\n",
      "loss: 0.513406  [ 6464/60000]\n",
      "loss: 0.425809  [12864/60000]\n",
      "loss: 0.475673  [19264/60000]\n",
      "loss: 0.395087  [25664/60000]\n",
      "loss: 0.442997  [32064/60000]\n",
      "loss: 0.381456  [38464/60000]\n",
      "loss: 0.445166  [44864/60000]\n",
      "loss: 0.553386  [51264/60000]\n",
      "loss: 0.372210  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.450732 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.308826  [   64/60000]\n",
      "loss: 0.335668  [ 6464/60000]\n",
      "loss: 0.365549  [12864/60000]\n",
      "loss: 0.554636  [19264/60000]\n",
      "loss: 0.342702  [25664/60000]\n",
      "loss: 0.765142  [32064/60000]\n",
      "loss: 0.597306  [38464/60000]\n",
      "loss: 0.610068  [44864/60000]\n",
      "loss: 0.432234  [51264/60000]\n",
      "loss: 0.601896  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.449409 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.419825  [   64/60000]\n",
      "loss: 0.380410  [ 6464/60000]\n",
      "loss: 0.328868  [12864/60000]\n",
      "loss: 0.464482  [19264/60000]\n",
      "loss: 0.290242  [25664/60000]\n",
      "loss: 0.533231  [32064/60000]\n",
      "loss: 0.436974  [38464/60000]\n",
      "loss: 0.359762  [44864/60000]\n",
      "loss: 0.371312  [51264/60000]\n",
      "loss: 0.574690  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.446565 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.354160  [   64/60000]\n",
      "loss: 0.466174  [ 6464/60000]\n",
      "loss: 0.464688  [12864/60000]\n",
      "loss: 0.544133  [19264/60000]\n",
      "loss: 0.378932  [25664/60000]\n",
      "loss: 0.515461  [32064/60000]\n",
      "loss: 0.306451  [38464/60000]\n",
      "loss: 0.471228  [44864/60000]\n",
      "loss: 0.433654  [51264/60000]\n",
      "loss: 0.492958  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.446723 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.473391  [   64/60000]\n",
      "loss: 0.617931  [ 6464/60000]\n",
      "loss: 0.415771  [12864/60000]\n",
      "loss: 0.353712  [19264/60000]\n",
      "loss: 0.342773  [25664/60000]\n",
      "loss: 0.556950  [32064/60000]\n",
      "loss: 0.428936  [38464/60000]\n",
      "loss: 0.326948  [44864/60000]\n",
      "loss: 0.400361  [51264/60000]\n",
      "loss: 0.391806  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.446054 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.325318  [   64/60000]\n",
      "loss: 0.359049  [ 6464/60000]\n",
      "loss: 0.407190  [12864/60000]\n",
      "loss: 0.319832  [19264/60000]\n",
      "loss: 0.211338  [25664/60000]\n",
      "loss: 0.239096  [32064/60000]\n",
      "loss: 0.544854  [38464/60000]\n",
      "loss: 0.444723  [44864/60000]\n",
      "loss: 0.343139  [51264/60000]\n",
      "loss: 0.307744  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.444957 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.367410  [   64/60000]\n",
      "loss: 0.397410  [ 6464/60000]\n",
      "loss: 0.451454  [12864/60000]\n",
      "loss: 0.445105  [19264/60000]\n",
      "loss: 0.261572  [25664/60000]\n",
      "loss: 0.417597  [32064/60000]\n",
      "loss: 0.506822  [38464/60000]\n",
      "loss: 0.538677  [44864/60000]\n",
      "loss: 0.419685  [51264/60000]\n",
      "loss: 0.434724  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.444805 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.355369  [   64/60000]\n",
      "loss: 0.326341  [ 6464/60000]\n",
      "loss: 0.412708  [12864/60000]\n",
      "loss: 0.488965  [19264/60000]\n",
      "loss: 0.457934  [25664/60000]\n",
      "loss: 0.582347  [32064/60000]\n",
      "loss: 0.386019  [38464/60000]\n",
      "loss: 0.368424  [44864/60000]\n",
      "loss: 0.667448  [51264/60000]\n",
      "loss: 0.299691  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.444274 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.474897  [   64/60000]\n",
      "loss: 0.407425  [ 6464/60000]\n",
      "loss: 0.407689  [12864/60000]\n",
      "loss: 0.317758  [19264/60000]\n",
      "loss: 0.375517  [25664/60000]\n",
      "loss: 0.376012  [32064/60000]\n",
      "loss: 0.398100  [38464/60000]\n",
      "loss: 0.425147  [44864/60000]\n",
      "loss: 0.475382  [51264/60000]\n",
      "loss: 0.331667  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.440683 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.400842  [   64/60000]\n",
      "loss: 0.430735  [ 6464/60000]\n",
      "loss: 0.540150  [12864/60000]\n",
      "loss: 0.489477  [19264/60000]\n",
      "loss: 0.299247  [25664/60000]\n",
      "loss: 0.305914  [32064/60000]\n",
      "loss: 0.403650  [38464/60000]\n",
      "loss: 0.294274  [44864/60000]\n",
      "loss: 0.447547  [51264/60000]\n",
      "loss: 0.292268  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.443760 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.317185  [   64/60000]\n",
      "loss: 0.710594  [ 6464/60000]\n",
      "loss: 0.221567  [12864/60000]\n",
      "loss: 0.586455  [19264/60000]\n",
      "loss: 0.425254  [25664/60000]\n",
      "loss: 0.430594  [32064/60000]\n",
      "loss: 0.479903  [38464/60000]\n",
      "loss: 0.414128  [44864/60000]\n",
      "loss: 0.278586  [51264/60000]\n",
      "loss: 0.487661  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.439511 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.446691  [   64/60000]\n",
      "loss: 0.462854  [ 6464/60000]\n",
      "loss: 0.397353  [12864/60000]\n",
      "loss: 0.685873  [19264/60000]\n",
      "loss: 0.237861  [25664/60000]\n",
      "loss: 0.330813  [32064/60000]\n",
      "loss: 0.366637  [38464/60000]\n",
      "loss: 0.416319  [44864/60000]\n",
      "loss: 0.296388  [51264/60000]\n",
      "loss: 0.396342  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.440709 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.394990  [   64/60000]\n",
      "loss: 0.419247  [ 6464/60000]\n",
      "loss: 0.247668  [12864/60000]\n",
      "loss: 0.503930  [19264/60000]\n",
      "loss: 0.395443  [25664/60000]\n",
      "loss: 0.523827  [32064/60000]\n",
      "loss: 0.330924  [38464/60000]\n",
      "loss: 0.375141  [44864/60000]\n",
      "loss: 0.291732  [51264/60000]\n",
      "loss: 0.282689  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.441059 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.458978  [   64/60000]\n",
      "loss: 0.242076  [ 6464/60000]\n",
      "loss: 0.383800  [12864/60000]\n",
      "loss: 0.238948  [19264/60000]\n",
      "loss: 0.317978  [25664/60000]\n",
      "loss: 0.451132  [32064/60000]\n",
      "loss: 0.314488  [38464/60000]\n",
      "loss: 0.541484  [44864/60000]\n",
      "loss: 0.513760  [51264/60000]\n",
      "loss: 0.447733  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.440220 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.256068  [   64/60000]\n",
      "loss: 0.532025  [ 6464/60000]\n",
      "loss: 0.588062  [12864/60000]\n",
      "loss: 0.363096  [19264/60000]\n",
      "loss: 0.526590  [25664/60000]\n",
      "loss: 0.311075  [32064/60000]\n",
      "loss: 0.429889  [38464/60000]\n",
      "loss: 0.356518  [44864/60000]\n",
      "loss: 0.423693  [51264/60000]\n",
      "loss: 0.455022  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.436759 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.275563  [   64/60000]\n",
      "loss: 0.379813  [ 6464/60000]\n",
      "loss: 0.613127  [12864/60000]\n",
      "loss: 0.517655  [19264/60000]\n",
      "loss: 0.516766  [25664/60000]\n",
      "loss: 0.527327  [32064/60000]\n",
      "loss: 0.532779  [38464/60000]\n",
      "loss: 0.392423  [44864/60000]\n",
      "loss: 0.368602  [51264/60000]\n",
      "loss: 0.473085  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.438063 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.412757  [   64/60000]\n",
      "loss: 0.301963  [ 6464/60000]\n",
      "loss: 0.520279  [12864/60000]\n",
      "loss: 0.291313  [19264/60000]\n",
      "loss: 0.440612  [25664/60000]\n",
      "loss: 0.355321  [32064/60000]\n",
      "loss: 0.484321  [38464/60000]\n",
      "loss: 0.312424  [44864/60000]\n",
      "loss: 0.421472  [51264/60000]\n",
      "loss: 0.363304  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.437151 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beforewe will have a look at whether this model can now differentiate a trouser from a t-shirt and ankle boot, we shall save the model and its parameter. Depending on the power of your computer, it is likely that the above process took quite a while and if you can avoid it you do not want to redo this work (after all, how many cups of tea can you drink!).\n",
    "\n",
    "The model and its parameters can be saved as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_{}_{}'.format(int(datetime.timestamp(datetime.now())), epochs)\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has now saved the model (specification and optimised parameters) in a file called `model_XXXX_100` where the `XXXX` will be replaced with a number representing the day and time at which you saved the model.\n",
    "\n",
    "The next time you open upir code and work at it, you do not have to re-estimate your model, but you can re-initiate it (which means that your model class definition has to have been run) and then you just reuploade the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load('model_1697308318_100'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall how, before training the model, it was unable to detect that a picture depicted an ankle boot. So let's try this again. We feed the image back into the model (`ds_train[15][0]`) and check out the probabilities for the 10 clsses. Ankle boots are the last class so we are hoping for nine numbers close to 0 followed by a number close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3886e-09, 2.4075e-11, 1.6684e-10, 1.2697e-10, 2.4469e-11, 1.5385e-03,\n",
      "         1.6970e-09, 8.7893e-03, 5.5127e-06, 9.8967e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = model(ds_train[15][0])\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "print(pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a success. The model tells us that there is a 98.97% probability that the item is indeed an ankle boot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
